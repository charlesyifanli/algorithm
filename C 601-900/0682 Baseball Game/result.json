{"traceEvents": [{"ph": "M", "pid": 8624, "tid": 8624, "name": "process_name", "args": {"name": "MainProcess"}}, {"ph": "M", "pid": 8624, "tid": 14252, "name": "thread_name", "args": {"name": "MainThread"}}, {"pid": 8624, "tid": 14252, "ts": 9913123739.4, "ph": "X", "cat": "fee", "dur": 2.2, "name": "inner (C:\\Users\\charles\\.conda\\envs\\demo\\Lib\\typing.py:352)"}, {"pid": 8624, "tid": 14252, "ts": 9913123735.6, "ph": "X", "cat": "fee", "dur": 7.3, "name": "Solution (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:4)"}, {"pid": 8624, "tid": 14252, "ts": 9913123733.5, "ph": "X", "cat": "fee", "dur": 28.9, "name": "builtins.__build_class__"}, {"pid": 8624, "tid": 14252, "ts": 9913123769.8, "ph": "X", "cat": "fee", "dur": 0.2, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123770.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123771.2, "ph": "X", "cat": "fee", "dur": 0.2, "name": "list.pop"}, {"pid": 8624, "tid": 14252, "ts": 9913123772.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123772.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123773.4, "ph": "X", "cat": "fee", "dur": 0.6, "name": "builtins.sum"}, {"pid": 8624, "tid": 14252, "ts": 9913123767.7, "ph": "X", "cat": "fee", "dur": 6.4, "name": "calPoints (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:5)"}, {"pid": 8624, "tid": 14252, "ts": 9913123776.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123777.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123778.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123778.8, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.pop"}, {"pid": 8624, "tid": 14252, "ts": 9913123779.4, "ph": "X", "cat": "fee", "dur": 0.02, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123780.0, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123780.6, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123781.1, "ph": "X", "cat": "fee", "dur": 0.1, "name": "list.append"}, {"pid": 8624, "tid": 14252, "ts": 9913123781.4, "ph": "X", "cat": "fee", "dur": 0.3, "name": "builtins.sum"}, {"pid": 8624, "tid": 14252, "ts": 9913123775.4, "ph": "X", "cat": "fee", "dur": 6.4, "name": "calPoints (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:5)"}, {"pid": 8624, "tid": 14252, "ts": 9913123782.3, "ph": "X", "cat": "fee", "dur": 199.0, "name": "builtins.print"}, {"pid": 8624, "tid": 14252, "ts": 9913123765.0, "ph": "X", "cat": "fee", "dur": 217.3, "name": "test_cal_points (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:20)"}, {"pid": 8624, "tid": 14252, "ts": 9913123726.7, "ph": "X", "cat": "fee", "dur": 257.0, "name": "<module> (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:1)"}, {"pid": 8624, "tid": 14252, "ts": 9913123724.1, "ph": "X", "cat": "fee", "dur": 261.1, "name": "builtins.exec"}], "viztracer_metadata": {"overflow": false, "version": "0.16.1"}, "file_info": {"files": {"C:\\Users\\charles\\.conda\\envs\\demo\\Lib\\typing.py": ["\"\"\"\nThe typing module: Support for gradual typing as defined by PEP 484 and subsequent PEPs.\n\nAmong other things, the module includes the following:\n* Generic, Protocol, and internal machinery to support generic aliases.\n  All subscripted types like X[int], Union[int, str] are generic aliases.\n* Various \"special forms\" that have unique meanings in type annotations:\n  NoReturn, Never, ClassVar, Self, Concatenate, Unpack, and others.\n* Classes whose instances can be type arguments to generic classes and functions:\n  TypeVar, ParamSpec, TypeVarTuple.\n* Public helper functions: get_type_hints, overload, cast, final, and others.\n* Several protocols to support duck-typing:\n  SupportsFloat, SupportsIndex, SupportsAbs, and others.\n* Special types: NewType, NamedTuple, TypedDict.\n* Deprecated wrapper submodules for re and io related types.\n* Deprecated aliases for builtin types and collections.abc ABCs.\n\nAny name not present in __all__ is an implementation detail\nthat may be changed without notice. Use at your own risk!\n\"\"\"\n\nfrom abc import abstractmethod, ABCMeta\nimport collections\nfrom collections import defaultdict\nimport collections.abc\nimport contextlib\nimport functools\nimport operator\nimport re as stdlib_re  # Avoid confusion with the re we export.\nimport sys\nimport types\nimport warnings\nfrom types import WrapperDescriptorType, MethodWrapperType, MethodDescriptorType, GenericAlias\n\n\ntry:\n    from _typing import _idfunc\nexcept ImportError:\n    def _idfunc(_, x):\n        return x\n\n# Please keep __all__ alphabetized within each category.\n__all__ = [\n    # Super-special typing primitives.\n    'Annotated',\n    'Any',\n    'Callable',\n    'ClassVar',\n    'Concatenate',\n    'Final',\n    'ForwardRef',\n    'Generic',\n    'Literal',\n    'Optional',\n    'ParamSpec',\n    'Protocol',\n    'Tuple',\n    'Type',\n    'TypeVar',\n    'TypeVarTuple',\n    'Union',\n\n    # ABCs (from collections.abc).\n    'AbstractSet',  # collections.abc.Set.\n    'ByteString',\n    'Container',\n    'ContextManager',\n    'Hashable',\n    'ItemsView',\n    'Iterable',\n    'Iterator',\n    'KeysView',\n    'Mapping',\n    'MappingView',\n    'MutableMapping',\n    'MutableSequence',\n    'MutableSet',\n    'Sequence',\n    'Sized',\n    'ValuesView',\n    'Awaitable',\n    'AsyncIterator',\n    'AsyncIterable',\n    'Coroutine',\n    'Collection',\n    'AsyncGenerator',\n    'AsyncContextManager',\n\n    # Structural checks, a.k.a. protocols.\n    'Reversible',\n    'SupportsAbs',\n    'SupportsBytes',\n    'SupportsComplex',\n    'SupportsFloat',\n    'SupportsIndex',\n    'SupportsInt',\n    'SupportsRound',\n\n    # Concrete collection types.\n    'ChainMap',\n    'Counter',\n    'Deque',\n    'Dict',\n    'DefaultDict',\n    'List',\n    'OrderedDict',\n    'Set',\n    'FrozenSet',\n    'NamedTuple',  # Not really a type.\n    'TypedDict',  # Not really a type.\n    'Generator',\n\n    # Other concrete types.\n    'BinaryIO',\n    'IO',\n    'Match',\n    'Pattern',\n    'TextIO',\n\n    # One-off things.\n    'AnyStr',\n    'assert_type',\n    'assert_never',\n    'cast',\n    'clear_overloads',\n    'dataclass_transform',\n    'final',\n    'get_args',\n    'get_origin',\n    'get_overloads',\n    'get_type_hints',\n    'is_typeddict',\n    'LiteralString',\n    'Never',\n    'NewType',\n    'no_type_check',\n    'no_type_check_decorator',\n    'NoReturn',\n    'NotRequired',\n    'overload',\n    'ParamSpecArgs',\n    'ParamSpecKwargs',\n    'Required',\n    'reveal_type',\n    'runtime_checkable',\n    'Self',\n    'Text',\n    'TYPE_CHECKING',\n    'TypeAlias',\n    'TypeGuard',\n    'Unpack',\n]\n\n# The pseudo-submodules 're' and 'io' are part of the public\n# namespace, but excluded from __all__ because they might stomp on\n# legitimate imports of those modules.\n\n\ndef _type_convert(arg, module=None, *, allow_special_forms=False):\n    \"\"\"For converting None to type(None), and strings to ForwardRef.\"\"\"\n    if arg is None:\n        return type(None)\n    if isinstance(arg, str):\n        return ForwardRef(arg, module=module, is_class=allow_special_forms)\n    return arg\n\n\ndef _type_check(arg, msg, is_argument=True, module=None, *, allow_special_forms=False):\n    \"\"\"Check that the argument is a type, and return it (internal helper).\n\n    As a special case, accept None and return type(None) instead. Also wrap strings\n    into ForwardRef instances. Consider several corner cases, for example plain\n    special forms like Union are not valid, while Union[int, str] is OK, etc.\n    The msg argument is a human-readable error message, e.g.::\n\n        \"Union[arg, ...]: arg should be a type.\"\n\n    We append the repr() of the actual value (truncated to 100 chars).\n    \"\"\"\n    invalid_generic_forms = (Generic, Protocol)\n    if not allow_special_forms:\n        invalid_generic_forms += (ClassVar,)\n        if is_argument:\n            invalid_generic_forms += (Final,)\n\n    arg = _type_convert(arg, module=module, allow_special_forms=allow_special_forms)\n    if (isinstance(arg, _GenericAlias) and\n            arg.__origin__ in invalid_generic_forms):\n        raise TypeError(f\"{arg} is not valid as type argument\")\n    if arg in (Any, LiteralString, NoReturn, Never, Self, TypeAlias):\n        return arg\n    if allow_special_forms and arg in (ClassVar, Final):\n        return arg\n    if isinstance(arg, _SpecialForm) or arg in (Generic, Protocol):\n        raise TypeError(f\"Plain {arg} is not valid as type argument\")\n    if type(arg) is tuple:\n        raise TypeError(f\"{msg} Got {arg!r:.100}.\")\n    return arg\n\n\ndef _is_param_expr(arg):\n    return arg is ... or isinstance(arg,\n            (tuple, list, ParamSpec, _ConcatenateGenericAlias))\n\n\ndef _should_unflatten_callable_args(typ, args):\n    \"\"\"Internal helper for munging collections.abc.Callable's __args__.\n\n    The canonical representation for a Callable's __args__ flattens the\n    argument types, see https://github.com/python/cpython/issues/86361.\n\n    For example::\n\n        assert collections.abc.Callable[[int, int], str].__args__ == (int, int, str)\n        assert collections.abc.Callable[ParamSpec, str].__args__ == (ParamSpec, str)\n\n    As a result, if we need to reconstruct the Callable from its __args__,\n    we need to unflatten it.\n    \"\"\"\n    return (\n        typ.__origin__ is collections.abc.Callable\n        and not (len(args) == 2 and _is_param_expr(args[0]))\n    )\n\n\ndef _type_repr(obj):\n    \"\"\"Return the repr() of an object, special-casing types (internal helper).\n\n    If obj is a type, we return a shorter version than the default\n    type.__repr__, based on the module and qualified name, which is\n    typically enough to uniquely identify a type.  For everything\n    else, we fall back on repr(obj).\n    \"\"\"\n    if isinstance(obj, types.GenericAlias):\n        return repr(obj)\n    if isinstance(obj, type):\n        if obj.__module__ == 'builtins':\n            return obj.__qualname__\n        return f'{obj.__module__}.{obj.__qualname__}'\n    if obj is ...:\n        return('...')\n    if isinstance(obj, types.FunctionType):\n        return obj.__name__\n    return repr(obj)\n\n\ndef _collect_parameters(args):\n    \"\"\"Collect all type variables and parameter specifications in args\n    in order of first appearance (lexicographic order).\n\n    For example::\n\n        assert _collect_parameters((T, Callable[P, T])) == (T, P)\n    \"\"\"\n    parameters = []\n    for t in args:\n        if isinstance(t, type):\n            # We don't want __parameters__ descriptor of a bare Python class.\n            pass\n        elif isinstance(t, tuple):\n            # `t` might be a tuple, when `ParamSpec` is substituted with\n            # `[T, int]`, or `[int, *Ts]`, etc.\n            for x in t:\n                for collected in _collect_parameters([x]):\n                    if collected not in parameters:\n                        parameters.append(collected)\n        elif hasattr(t, '__typing_subst__'):\n            if t not in parameters:\n                parameters.append(t)\n        else:\n            for x in getattr(t, '__parameters__', ()):\n                if x not in parameters:\n                    parameters.append(x)\n    return tuple(parameters)\n\n\ndef _check_generic(cls, parameters, elen):\n    \"\"\"Check correct count for parameters of a generic cls (internal helper).\n\n    This gives a nice error message in case of count mismatch.\n    \"\"\"\n    if not elen:\n        raise TypeError(f\"{cls} is not a generic class\")\n    alen = len(parameters)\n    if alen != elen:\n        raise TypeError(f\"Too {'many' if alen > elen else 'few'} arguments for {cls};\"\n                        f\" actual {alen}, expected {elen}\")\n\ndef _unpack_args(args):\n    newargs = []\n    for arg in args:\n        subargs = getattr(arg, '__typing_unpacked_tuple_args__', None)\n        if subargs is not None and not (subargs and subargs[-1] is ...):\n            newargs.extend(subargs)\n        else:\n            newargs.append(arg)\n    return newargs\n\ndef _deduplicate(params):\n    # Weed out strict duplicates, preserving the first of each occurrence.\n    all_params = set(params)\n    if len(all_params) < len(params):\n        new_params = []\n        for t in params:\n            if t in all_params:\n                new_params.append(t)\n                all_params.remove(t)\n        params = new_params\n        assert not all_params, all_params\n    return params\n\n\ndef _remove_dups_flatten(parameters):\n    \"\"\"Internal helper for Union creation and substitution.\n\n    Flatten Unions among parameters, then remove duplicates.\n    \"\"\"\n    # Flatten out Union[Union[...], ...].\n    params = []\n    for p in parameters:\n        if isinstance(p, (_UnionGenericAlias, types.UnionType)):\n            params.extend(p.__args__)\n        else:\n            params.append(p)\n\n    return tuple(_deduplicate(params))\n\n\ndef _flatten_literal_params(parameters):\n    \"\"\"Internal helper for Literal creation: flatten Literals among parameters.\"\"\"\n    params = []\n    for p in parameters:\n        if isinstance(p, _LiteralGenericAlias):\n            params.extend(p.__args__)\n        else:\n            params.append(p)\n    return tuple(params)\n\n\n_cleanups = []\n\n\ndef _tp_cache(func=None, /, *, typed=False):\n    \"\"\"Internal wrapper caching __getitem__ of generic types.\n\n    For non-hashable arguments, the original function is used as a fallback.\n    \"\"\"\n    def decorator(func):\n        cached = functools.lru_cache(typed=typed)(func)\n        _cleanups.append(cached.cache_clear)\n\n        @functools.wraps(func)\n        def inner(*args, **kwds):\n            try:\n                return cached(*args, **kwds)\n            except TypeError:\n                pass  # All real errors (not unhashable args) are raised below.\n            return func(*args, **kwds)\n        return inner\n\n    if func is not None:\n        return decorator(func)\n\n    return decorator\n\ndef _eval_type(t, globalns, localns, recursive_guard=frozenset()):\n    \"\"\"Evaluate all forward references in the given type t.\n\n    For use of globalns and localns see the docstring for get_type_hints().\n    recursive_guard is used to prevent infinite recursion with a recursive\n    ForwardRef.\n    \"\"\"\n    if isinstance(t, ForwardRef):\n        return t._evaluate(globalns, localns, recursive_guard)\n    if isinstance(t, (_GenericAlias, GenericAlias, types.UnionType)):\n        if isinstance(t, GenericAlias):\n            args = tuple(\n                ForwardRef(arg) if isinstance(arg, str) else arg\n                for arg in t.__args__\n            )\n            is_unpacked = t.__unpacked__\n            if _should_unflatten_callable_args(t, args):\n                t = t.__origin__[(args[:-1], args[-1])]\n            else:\n                t = t.__origin__[args]\n            if is_unpacked:\n                t = Unpack[t]\n        ev_args = tuple(_eval_type(a, globalns, localns, recursive_guard) for a in t.__args__)\n        if ev_args == t.__args__:\n            return t\n        if isinstance(t, GenericAlias):\n            return GenericAlias(t.__origin__, ev_args)\n        if isinstance(t, types.UnionType):\n            return functools.reduce(operator.or_, ev_args)\n        else:\n            return t.copy_with(ev_args)\n    return t\n\n\nclass _Final:\n    \"\"\"Mixin to prohibit subclassing.\"\"\"\n\n    __slots__ = ('__weakref__',)\n\n    def __init_subclass__(cls, /, *args, **kwds):\n        if '_root' not in kwds:\n            raise TypeError(\"Cannot subclass special typing classes\")\n\nclass _Immutable:\n    \"\"\"Mixin to indicate that object should not be copied.\"\"\"\n\n    __slots__ = ()\n\n    def __copy__(self):\n        return self\n\n    def __deepcopy__(self, memo):\n        return self\n\n\nclass _NotIterable:\n    \"\"\"Mixin to prevent iteration, without being compatible with Iterable.\n\n    That is, we could do::\n\n        def __iter__(self): raise TypeError()\n\n    But this would make users of this mixin duck type-compatible with\n    collections.abc.Iterable - isinstance(foo, Iterable) would be True.\n\n    Luckily, we can instead prevent iteration by setting __iter__ to None, which\n    is treated specially.\n    \"\"\"\n\n    __slots__ = ()\n    __iter__ = None\n\n\n# Internal indicator of special typing constructs.\n# See __doc__ instance attribute for specific docs.\nclass _SpecialForm(_Final, _NotIterable, _root=True):\n    __slots__ = ('_name', '__doc__', '_getitem')\n\n    def __init__(self, getitem):\n        self._getitem = getitem\n        self._name = getitem.__name__\n        self.__doc__ = getitem.__doc__\n\n    def __getattr__(self, item):\n        if item in {'__name__', '__qualname__'}:\n            return self._name\n\n        raise AttributeError(item)\n\n    def __mro_entries__(self, bases):\n        raise TypeError(f\"Cannot subclass {self!r}\")\n\n    def __repr__(self):\n        return 'typing.' + self._name\n\n    def __reduce__(self):\n        return self._name\n\n    def __call__(self, *args, **kwds):\n        raise TypeError(f\"Cannot instantiate {self!r}\")\n\n    def __or__(self, other):\n        return Union[self, other]\n\n    def __ror__(self, other):\n        return Union[other, self]\n\n    def __instancecheck__(self, obj):\n        raise TypeError(f\"{self} cannot be used with isinstance()\")\n\n    def __subclasscheck__(self, cls):\n        raise TypeError(f\"{self} cannot be used with issubclass()\")\n\n    @_tp_cache\n    def __getitem__(self, parameters):\n        return self._getitem(self, parameters)\n\n\nclass _LiteralSpecialForm(_SpecialForm, _root=True):\n    def __getitem__(self, parameters):\n        if not isinstance(parameters, tuple):\n            parameters = (parameters,)\n        return self._getitem(self, *parameters)\n\n\nclass _AnyMeta(type):\n    def __instancecheck__(self, obj):\n        if self is Any:\n            raise TypeError(\"typing.Any cannot be used with isinstance()\")\n        return super().__instancecheck__(obj)\n\n    def __repr__(self):\n        if self is Any:\n            return \"typing.Any\"\n        return super().__repr__()  # respect to subclasses\n\n\nclass Any(metaclass=_AnyMeta):\n    \"\"\"Special type indicating an unconstrained type.\n\n    - Any is compatible with every type.\n    - Any assumed to have all methods.\n    - All values assumed to be instances of Any.\n\n    Note that all the above statements are true from the point of view of\n    static type checkers. At runtime, Any should not be used with instance\n    checks.\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        if cls is Any:\n            raise TypeError(\"Any cannot be instantiated\")\n        return super().__new__(cls, *args, **kwargs)\n\n\n@_SpecialForm\ndef NoReturn(self, parameters):\n    \"\"\"Special type indicating functions that never return.\n\n    Example::\n\n        from typing import NoReturn\n\n        def stop() -> NoReturn:\n            raise Exception('no way')\n\n    NoReturn can also be used as a bottom type, a type that\n    has no values. Starting in Python 3.11, the Never type should\n    be used for this concept instead. Type checkers should treat the two\n    equivalently.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n# This is semantically identical to NoReturn, but it is implemented\n# separately so that type checkers can distinguish between the two\n# if they want.\n@_SpecialForm\ndef Never(self, parameters):\n    \"\"\"The bottom type, a type that has no members.\n\n    This can be used to define a function that should never be\n    called, or a function that never returns::\n\n        from typing import Never\n\n        def never_call_me(arg: Never) -> None:\n            pass\n\n        def int_or_str(arg: int | str) -> None:\n            never_call_me(arg)  # type checker error\n            match arg:\n                case int():\n                    print(\"It's an int\")\n                case str():\n                    print(\"It's a str\")\n                case _:\n                    never_call_me(arg)  # OK, arg is of type Never\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n\n@_SpecialForm\ndef Self(self, parameters):\n    \"\"\"Used to spell the type of \"self\" in classes.\n\n    Example::\n\n        from typing import Self\n\n        class Foo:\n            def return_self(self) -> Self:\n                ...\n                return self\n\n    This is especially useful for:\n        - classmethods that are used as alternative constructors\n        - annotating an `__enter__` method which returns self\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n\n@_SpecialForm\ndef LiteralString(self, parameters):\n    \"\"\"Represents an arbitrary literal string.\n\n    Example::\n\n        from typing import LiteralString\n\n        def run_query(sql: LiteralString) -> None:\n            ...\n\n        def caller(arbitrary_string: str, literal_string: LiteralString) -> None:\n            run_query(\"SELECT * FROM students\")  # OK\n            run_query(literal_string)  # OK\n            run_query(\"SELECT * FROM \" + literal_string)  # OK\n            run_query(arbitrary_string)  # type checker error\n            run_query(  # type checker error\n                f\"SELECT * FROM students WHERE name = {arbitrary_string}\"\n            )\n\n    Only string literals and other LiteralStrings are compatible\n    with LiteralString. This provides a tool to help prevent\n    security issues such as SQL injection.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n\n@_SpecialForm\ndef ClassVar(self, parameters):\n    \"\"\"Special type construct to mark class variables.\n\n    An annotation wrapped in ClassVar indicates that a given\n    attribute is intended to be used as a class variable and\n    should not be set on instances of that class.\n\n    Usage::\n\n        class Starship:\n            stats: ClassVar[dict[str, int]] = {} # class variable\n            damage: int = 10                     # instance variable\n\n    ClassVar accepts only types and cannot be further subscribed.\n\n    Note that ClassVar is not a class itself, and should not\n    be used with isinstance() or issubclass().\n    \"\"\"\n    item = _type_check(parameters, f'{self} accepts only single type.')\n    return _GenericAlias(self, (item,))\n\n@_SpecialForm\ndef Final(self, parameters):\n    \"\"\"Special typing construct to indicate final names to type checkers.\n\n    A final name cannot be re-assigned or overridden in a subclass.\n\n    For example::\n\n        MAX_SIZE: Final = 9000\n        MAX_SIZE += 1  # Error reported by type checker\n\n        class Connection:\n            TIMEOUT: Final[int] = 10\n\n        class FastConnector(Connection):\n            TIMEOUT = 1  # Error reported by type checker\n\n    There is no runtime checking of these properties.\n    \"\"\"\n    item = _type_check(parameters, f'{self} accepts only single type.')\n    return _GenericAlias(self, (item,))\n\n@_SpecialForm\ndef Union(self, parameters):\n    \"\"\"Union type; Union[X, Y] means either X or Y.\n\n    On Python 3.10 and higher, the | operator\n    can also be used to denote unions;\n    X | Y means the same thing to the type checker as Union[X, Y].\n\n    To define a union, use e.g. Union[int, str]. Details:\n    - The arguments must be types and there must be at least one.\n    - None as an argument is a special case and is replaced by\n      type(None).\n    - Unions of unions are flattened, e.g.::\n\n        assert Union[Union[int, str], float] == Union[int, str, float]\n\n    - Unions of a single argument vanish, e.g.::\n\n        assert Union[int] == int  # The constructor actually returns int\n\n    - Redundant arguments are skipped, e.g.::\n\n        assert Union[int, str, int] == Union[int, str]\n\n    - When comparing unions, the argument order is ignored, e.g.::\n\n        assert Union[int, str] == Union[str, int]\n\n    - You cannot subclass or instantiate a union.\n    - You can use Optional[X] as a shorthand for Union[X, None].\n    \"\"\"\n    if parameters == ():\n        raise TypeError(\"Cannot take a Union of no types.\")\n    if not isinstance(parameters, tuple):\n        parameters = (parameters,)\n    msg = \"Union[arg, ...]: each arg must be a type.\"\n    parameters = tuple(_type_check(p, msg) for p in parameters)\n    parameters = _remove_dups_flatten(parameters)\n    if len(parameters) == 1:\n        return parameters[0]\n    if len(parameters) == 2 and type(None) in parameters:\n        return _UnionGenericAlias(self, parameters, name=\"Optional\")\n    return _UnionGenericAlias(self, parameters)\n\n@_SpecialForm\ndef Optional(self, parameters):\n    \"\"\"Optional[X] is equivalent to Union[X, None].\"\"\"\n    arg = _type_check(parameters, f\"{self} requires a single type.\")\n    return Union[arg, type(None)]\n\n@_LiteralSpecialForm\n@_tp_cache(typed=True)\ndef Literal(self, *parameters):\n    \"\"\"Special typing form to define literal types (a.k.a. value types).\n\n    This form can be used to indicate to type checkers that the corresponding\n    variable or function parameter has a value equivalent to the provided\n    literal (or one of several literals)::\n\n        def validate_simple(data: Any) -> Literal[True]:  # always returns True\n            ...\n\n        MODE = Literal['r', 'rb', 'w', 'wb']\n        def open_helper(file: str, mode: MODE) -> str:\n            ...\n\n        open_helper('/some/path', 'r')  # Passes type check\n        open_helper('/other/path', 'typo')  # Error in type checker\n\n    Literal[...] cannot be subclassed. At runtime, an arbitrary value\n    is allowed as type argument to Literal[...], but type checkers may\n    impose restrictions.\n    \"\"\"\n    # There is no '_type_check' call because arguments to Literal[...] are\n    # values, not types.\n    parameters = _flatten_literal_params(parameters)\n\n    try:\n        parameters = tuple(p for p, _ in _deduplicate(list(_value_and_type_iter(parameters))))\n    except TypeError:  # unhashable parameters\n        pass\n\n    return _LiteralGenericAlias(self, parameters)\n\n\n@_SpecialForm\ndef TypeAlias(self, parameters):\n    \"\"\"Special form for marking type aliases.\n\n    Use TypeAlias to indicate that an assignment should\n    be recognized as a proper type alias definition by type\n    checkers.\n\n    For example::\n\n        Predicate: TypeAlias = Callable[..., bool]\n\n    It's invalid when used anywhere except as in the example above.\n    \"\"\"\n    raise TypeError(f\"{self} is not subscriptable\")\n\n\n@_SpecialForm\ndef Concatenate(self, parameters):\n    \"\"\"Special form for annotating higher-order functions.\n\n    ``Concatenate`` can be used in conjunction with ``ParamSpec`` and\n    ``Callable`` to represent a higher-order function which adds, removes or\n    transforms the parameters of a callable.\n\n    For example::\n\n        Callable[Concatenate[int, P], int]\n\n    See PEP 612 for detailed information.\n    \"\"\"\n    if parameters == ():\n        raise TypeError(\"Cannot take a Concatenate of no types.\")\n    if not isinstance(parameters, tuple):\n        parameters = (parameters,)\n    if not (parameters[-1] is ... or isinstance(parameters[-1], ParamSpec)):\n        raise TypeError(\"The last parameter to Concatenate should be a \"\n                        \"ParamSpec variable or ellipsis.\")\n    msg = \"Concatenate[arg, ...]: each arg must be a type.\"\n    parameters = (*(_type_check(p, msg) for p in parameters[:-1]), parameters[-1])\n    return _ConcatenateGenericAlias(self, parameters,\n                                    _paramspec_tvars=True)\n\n\n@_SpecialForm\ndef TypeGuard(self, parameters):\n    \"\"\"Special typing construct for marking user-defined type guard functions.\n\n    ``TypeGuard`` can be used to annotate the return type of a user-defined\n    type guard function.  ``TypeGuard`` only accepts a single type argument.\n    At runtime, functions marked this way should return a boolean.\n\n    ``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static\n    type checkers to determine a more precise type of an expression within a\n    program's code flow.  Usually type narrowing is done by analyzing\n    conditional code flow and applying the narrowing to a block of code.  The\n    conditional expression here is sometimes referred to as a \"type guard\".\n\n    Sometimes it would be convenient to use a user-defined boolean function\n    as a type guard.  Such a function should use ``TypeGuard[...]`` as its\n    return type to alert static type checkers to this intention.\n\n    Using  ``-> TypeGuard`` tells the static type checker that for a given\n    function:\n\n    1. The return value is a boolean.\n    2. If the return value is ``True``, the type of its argument\n       is the type inside ``TypeGuard``.\n\n       For example::\n\n           def is_str(val: Union[str, float]):\n               # \"isinstance\" type guard\n               if isinstance(val, str):\n                   # Type of ``val`` is narrowed to ``str``\n                   ...\n               else:\n                   # Else, type of ``val`` is narrowed to ``float``.\n                   ...\n\n    Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower\n    form of ``TypeA`` (it can even be a wider form) and this may lead to\n    type-unsafe results.  The main reason is to allow for things like\n    narrowing ``List[object]`` to ``List[str]`` even though the latter is not\n    a subtype of the former, since ``List`` is invariant.  The responsibility of\n    writing type-safe type guards is left to the user.\n\n    ``TypeGuard`` also works with type variables.  For more information, see\n    PEP 647 (User-Defined Type Guards).\n    \"\"\"\n    item = _type_check(parameters, f'{self} accepts only single type.')\n    return _GenericAlias(self, (item,))\n\n\nclass ForwardRef(_Final, _root=True):\n    \"\"\"Internal wrapper to hold a forward reference.\"\"\"\n\n    __slots__ = ('__forward_arg__', '__forward_code__',\n                 '__forward_evaluated__', '__forward_value__',\n                 '__forward_is_argument__', '__forward_is_class__',\n                 '__forward_module__')\n\n    def __init__(self, arg, is_argument=True, module=None, *, is_class=False):\n        if not isinstance(arg, str):\n            raise TypeError(f\"Forward reference must be a string -- got {arg!r}\")\n\n        # If we do `def f(*args: *Ts)`, then we'll have `arg = '*Ts'`.\n        # Unfortunately, this isn't a valid expression on its own, so we\n        # do the unpacking manually.\n        if arg[0] == '*':\n            arg_to_compile = f'({arg},)[0]'  # E.g. (*Ts,)[0] or (*tuple[int, int],)[0]\n        else:\n            arg_to_compile = arg\n        try:\n            code = compile(arg_to_compile, '<string>', 'eval')\n        except SyntaxError:\n            raise SyntaxError(f\"Forward reference must be an expression -- got {arg!r}\")\n\n        self.__forward_arg__ = arg\n        self.__forward_code__ = code\n        self.__forward_evaluated__ = False\n        self.__forward_value__ = None\n        self.__forward_is_argument__ = is_argument\n        self.__forward_is_class__ = is_class\n        self.__forward_module__ = module\n\n    def _evaluate(self, globalns, localns, recursive_guard):\n        if self.__forward_arg__ in recursive_guard:\n            return self\n        if not self.__forward_evaluated__ or localns is not globalns:\n            if globalns is None and localns is None:\n                globalns = localns = {}\n            elif globalns is None:\n                globalns = localns\n            elif localns is None:\n                localns = globalns\n            if self.__forward_module__ is not None:\n                globalns = getattr(\n                    sys.modules.get(self.__forward_module__, None), '__dict__', globalns\n                )\n            type_ = _type_check(\n                eval(self.__forward_code__, globalns, localns),\n                \"Forward references must evaluate to types.\",\n                is_argument=self.__forward_is_argument__,\n                allow_special_forms=self.__forward_is_class__,\n            )\n            self.__forward_value__ = _eval_type(\n                type_, globalns, localns, recursive_guard | {self.__forward_arg__}\n            )\n            self.__forward_evaluated__ = True\n        return self.__forward_value__\n\n    def __eq__(self, other):\n        if not isinstance(other, ForwardRef):\n            return NotImplemented\n        if self.__forward_evaluated__ and other.__forward_evaluated__:\n            return (self.__forward_arg__ == other.__forward_arg__ and\n                    self.__forward_value__ == other.__forward_value__)\n        return (self.__forward_arg__ == other.__forward_arg__ and\n                self.__forward_module__ == other.__forward_module__)\n\n    def __hash__(self):\n        return hash((self.__forward_arg__, self.__forward_module__))\n\n    def __or__(self, other):\n        return Union[self, other]\n\n    def __ror__(self, other):\n        return Union[other, self]\n\n    def __repr__(self):\n        if self.__forward_module__ is None:\n            module_repr = ''\n        else:\n            module_repr = f', module={self.__forward_module__!r}'\n        return f'ForwardRef({self.__forward_arg__!r}{module_repr})'\n\n\ndef _is_unpacked_typevartuple(x: Any) -> bool:\n    return ((not isinstance(x, type)) and\n            getattr(x, '__typing_is_unpacked_typevartuple__', False))\n\n\ndef _is_typevar_like(x: Any) -> bool:\n    return isinstance(x, (TypeVar, ParamSpec)) or _is_unpacked_typevartuple(x)\n\n\nclass _PickleUsingNameMixin:\n    \"\"\"Mixin enabling pickling based on self.__name__.\"\"\"\n\n    def __reduce__(self):\n        return self.__name__\n\n\nclass _BoundVarianceMixin:\n    \"\"\"Mixin giving __init__ bound and variance arguments.\n\n    This is used by TypeVar and ParamSpec, which both employ the notions of\n    a type 'bound' (restricting type arguments to be a subtype of some\n    specified type) and type 'variance' (determining subtype relations between\n    generic types).\n    \"\"\"\n    def __init__(self, bound, covariant, contravariant):\n        \"\"\"Used to setup TypeVars and ParamSpec's bound, covariant and\n        contravariant attributes.\n        \"\"\"\n        if covariant and contravariant:\n            raise ValueError(\"Bivariant types are not supported.\")\n        self.__covariant__ = bool(covariant)\n        self.__contravariant__ = bool(contravariant)\n        if bound:\n            self.__bound__ = _type_check(bound, \"Bound must be a type.\")\n        else:\n            self.__bound__ = None\n\n    def __or__(self, right):\n        return Union[self, right]\n\n    def __ror__(self, left):\n        return Union[left, self]\n\n    def __repr__(self):\n        if self.__covariant__:\n            prefix = '+'\n        elif self.__contravariant__:\n            prefix = '-'\n        else:\n            prefix = '~'\n        return prefix + self.__name__\n\n\nclass TypeVar(_Final, _Immutable, _BoundVarianceMixin, _PickleUsingNameMixin,\n              _root=True):\n    \"\"\"Type variable.\n\n    Usage::\n\n      T = TypeVar('T')  # Can be anything\n      A = TypeVar('A', str, bytes)  # Must be str or bytes\n\n    Type variables exist primarily for the benefit of static type\n    checkers.  They serve as the parameters for generic types as well\n    as for generic function definitions.  See class Generic for more\n    information on generic types.  Generic functions work as follows:\n\n      def repeat(x: T, n: int) -> List[T]:\n          '''Return a list containing n references to x.'''\n          return [x]*n\n\n      def longest(x: A, y: A) -> A:\n          '''Return the longest of two strings.'''\n          return x if len(x) >= len(y) else y\n\n    The latter example's signature is essentially the overloading\n    of (str, str) -> str and (bytes, bytes) -> bytes.  Also note\n    that if the arguments are instances of some subclass of str,\n    the return type is still plain str.\n\n    At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.\n\n    Type variables defined with covariant=True or contravariant=True\n    can be used to declare covariant or contravariant generic types.\n    See PEP 484 for more details. By default generic types are invariant\n    in all type variables.\n\n    Type variables can be introspected. e.g.:\n\n      T.__name__ == 'T'\n      T.__constraints__ == ()\n      T.__covariant__ == False\n      T.__contravariant__ = False\n      A.__constraints__ == (str, bytes)\n\n    Note that only type variables defined in global scope can be pickled.\n    \"\"\"\n\n    def __init__(self, name, *constraints, bound=None,\n                 covariant=False, contravariant=False):\n        self.__name__ = name\n        super().__init__(bound, covariant, contravariant)\n        if constraints and bound is not None:\n            raise TypeError(\"Constraints cannot be combined with bound=...\")\n        if constraints and len(constraints) == 1:\n            raise TypeError(\"A single constraint is not allowed\")\n        msg = \"TypeVar(name, constraint, ...): constraints must be types.\"\n        self.__constraints__ = tuple(_type_check(t, msg) for t in constraints)\n        def_mod = _caller()\n        if def_mod != 'typing':\n            self.__module__ = def_mod\n\n    def __typing_subst__(self, arg):\n        msg = \"Parameters to generic types must be types.\"\n        arg = _type_check(arg, msg, is_argument=True)\n        if ((isinstance(arg, _GenericAlias) and arg.__origin__ is Unpack) or\n            (isinstance(arg, GenericAlias) and getattr(arg, '__unpacked__', False))):\n            raise TypeError(f\"{arg} is not valid as type argument\")\n        return arg\n\n\nclass TypeVarTuple(_Final, _Immutable, _PickleUsingNameMixin, _root=True):\n    \"\"\"Type variable tuple.\n\n    Usage:\n\n      Ts = TypeVarTuple('Ts')  # Can be given any name\n\n    Just as a TypeVar (type variable) is a placeholder for a single type,\n    a TypeVarTuple is a placeholder for an *arbitrary* number of types. For\n    example, if we define a generic class using a TypeVarTuple:\n\n      class C(Generic[*Ts]): ...\n\n    Then we can parameterize that class with an arbitrary number of type\n    arguments:\n\n      C[int]       # Fine\n      C[int, str]  # Also fine\n      C[()]        # Even this is fine\n\n    For more details, see PEP 646.\n\n    Note that only TypeVarTuples defined in global scope can be pickled.\n    \"\"\"\n\n    def __init__(self, name):\n        self.__name__ = name\n\n        # Used for pickling.\n        def_mod = _caller()\n        if def_mod != 'typing':\n            self.__module__ = def_mod\n\n    def __iter__(self):\n        yield Unpack[self]\n\n    def __repr__(self):\n        return self.__name__\n\n    def __typing_subst__(self, arg):\n        raise TypeError(\"Substitution of bare TypeVarTuple is not supported\")\n\n    def __typing_prepare_subst__(self, alias, args):\n        params = alias.__parameters__\n        typevartuple_index = params.index(self)\n        for param in params[typevartuple_index + 1:]:\n            if isinstance(param, TypeVarTuple):\n                raise TypeError(f\"More than one TypeVarTuple parameter in {alias}\")\n\n        alen = len(args)\n        plen = len(params)\n        left = typevartuple_index\n        right = plen - typevartuple_index - 1\n        var_tuple_index = None\n        fillarg = None\n        for k, arg in enumerate(args):\n            if not isinstance(arg, type):\n                subargs = getattr(arg, '__typing_unpacked_tuple_args__', None)\n                if subargs and len(subargs) == 2 and subargs[-1] is ...:\n                    if var_tuple_index is not None:\n                        raise TypeError(\"More than one unpacked arbitrary-length tuple argument\")\n                    var_tuple_index = k\n                    fillarg = subargs[0]\n        if var_tuple_index is not None:\n            left = min(left, var_tuple_index)\n            right = min(right, alen - var_tuple_index - 1)\n        elif left + right > alen:\n            raise TypeError(f\"Too few arguments for {alias};\"\n                            f\" actual {alen}, expected at least {plen-1}\")\n\n        return (\n            *args[:left],\n            *([fillarg]*(typevartuple_index - left)),\n            tuple(args[left: alen - right]),\n            *([fillarg]*(plen - right - left - typevartuple_index - 1)),\n            *args[alen - right:],\n        )\n\n\nclass ParamSpecArgs(_Final, _Immutable, _root=True):\n    \"\"\"The args for a ParamSpec object.\n\n    Given a ParamSpec object P, P.args is an instance of ParamSpecArgs.\n\n    ParamSpecArgs objects have a reference back to their ParamSpec:\n\n       P.args.__origin__ is P\n\n    This type is meant for runtime introspection and has no special meaning to\n    static type checkers.\n    \"\"\"\n    def __init__(self, origin):\n        self.__origin__ = origin\n\n    def __repr__(self):\n        return f\"{self.__origin__.__name__}.args\"\n\n    def __eq__(self, other):\n        if not isinstance(other, ParamSpecArgs):\n            return NotImplemented\n        return self.__origin__ == other.__origin__\n\n\nclass ParamSpecKwargs(_Final, _Immutable, _root=True):\n    \"\"\"The kwargs for a ParamSpec object.\n\n    Given a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.\n\n    ParamSpecKwargs objects have a reference back to their ParamSpec:\n\n       P.kwargs.__origin__ is P\n\n    This type is meant for runtime introspection and has no special meaning to\n    static type checkers.\n    \"\"\"\n    def __init__(self, origin):\n        self.__origin__ = origin\n\n    def __repr__(self):\n        return f\"{self.__origin__.__name__}.kwargs\"\n\n    def __eq__(self, other):\n        if not isinstance(other, ParamSpecKwargs):\n            return NotImplemented\n        return self.__origin__ == other.__origin__\n\n\nclass ParamSpec(_Final, _Immutable, _BoundVarianceMixin, _PickleUsingNameMixin,\n                _root=True):\n    \"\"\"Parameter specification variable.\n\n    Usage::\n\n       P = ParamSpec('P')\n\n    Parameter specification variables exist primarily for the benefit of static\n    type checkers.  They are used to forward the parameter types of one\n    callable to another callable, a pattern commonly found in higher order\n    functions and decorators.  They are only valid when used in ``Concatenate``,\n    or as the first argument to ``Callable``, or as parameters for user-defined\n    Generics.  See class Generic for more information on generic types.  An\n    example for annotating a decorator::\n\n       T = TypeVar('T')\n       P = ParamSpec('P')\n\n       def add_logging(f: Callable[P, T]) -> Callable[P, T]:\n           '''A type-safe decorator to add logging to a function.'''\n           def inner(*args: P.args, **kwargs: P.kwargs) -> T:\n               logging.info(f'{f.__name__} was called')\n               return f(*args, **kwargs)\n           return inner\n\n       @add_logging\n       def add_two(x: float, y: float) -> float:\n           '''Add two numbers together.'''\n           return x + y\n\n    Parameter specification variables can be introspected. e.g.:\n\n       P.__name__ == 'P'\n\n    Note that only parameter specification variables defined in global scope can\n    be pickled.\n    \"\"\"\n\n    @property\n    def args(self):\n        return ParamSpecArgs(self)\n\n    @property\n    def kwargs(self):\n        return ParamSpecKwargs(self)\n\n    def __init__(self, name, *, bound=None, covariant=False, contravariant=False):\n        self.__name__ = name\n        super().__init__(bound, covariant, contravariant)\n        def_mod = _caller()\n        if def_mod != 'typing':\n            self.__module__ = def_mod\n\n    def __typing_subst__(self, arg):\n        if isinstance(arg, (list, tuple)):\n            arg = tuple(_type_check(a, \"Expected a type.\") for a in arg)\n        elif not _is_param_expr(arg):\n            raise TypeError(f\"Expected a list of types, an ellipsis, \"\n                            f\"ParamSpec, or Concatenate. Got {arg}\")\n        return arg\n\n    def __typing_prepare_subst__(self, alias, args):\n        params = alias.__parameters__\n        i = params.index(self)\n        if i >= len(args):\n            raise TypeError(f\"Too few arguments for {alias}\")\n        # Special case where Z[[int, str, bool]] == Z[int, str, bool] in PEP 612.\n        if len(params) == 1 and not _is_param_expr(args[0]):\n            assert i == 0\n            args = (args,)\n        # Convert lists to tuples to help other libraries cache the results.\n        elif isinstance(args[i], list):\n            args = (*args[:i], tuple(args[i]), *args[i+1:])\n        return args\n\ndef _is_dunder(attr):\n    return attr.startswith('__') and attr.endswith('__')\n\nclass _BaseGenericAlias(_Final, _root=True):\n    \"\"\"The central part of the internal API.\n\n    This represents a generic version of type 'origin' with type arguments 'params'.\n    There are two kind of these aliases: user defined and special. The special ones\n    are wrappers around builtin collections and ABCs in collections.abc. These must\n    have 'name' always set. If 'inst' is False, then the alias can't be instantiated;\n    this is used by e.g. typing.List and typing.Dict.\n    \"\"\"\n\n    def __init__(self, origin, *, inst=True, name=None):\n        self._inst = inst\n        self._name = name\n        self.__origin__ = origin\n        self.__slots__ = None  # This is not documented.\n\n    def __call__(self, *args, **kwargs):\n        if not self._inst:\n            raise TypeError(f\"Type {self._name} cannot be instantiated; \"\n                            f\"use {self.__origin__.__name__}() instead\")\n        result = self.__origin__(*args, **kwargs)\n        try:\n            result.__orig_class__ = self\n        except AttributeError:\n            pass\n        return result\n\n    def __mro_entries__(self, bases):\n        res = []\n        if self.__origin__ not in bases:\n            res.append(self.__origin__)\n        i = bases.index(self)\n        for b in bases[i+1:]:\n            if isinstance(b, _BaseGenericAlias) or issubclass(b, Generic):\n                break\n        else:\n            res.append(Generic)\n        return tuple(res)\n\n    def __getattr__(self, attr):\n        if attr in {'__name__', '__qualname__'}:\n            return self._name or self.__origin__.__name__\n\n        # We are careful for copy and pickle.\n        # Also for simplicity we don't relay any dunder names\n        if '__origin__' in self.__dict__ and not _is_dunder(attr):\n            return getattr(self.__origin__, attr)\n        raise AttributeError(attr)\n\n    def __setattr__(self, attr, val):\n        if _is_dunder(attr) or attr in {'_name', '_inst', '_nparams',\n                                        '_paramspec_tvars'}:\n            super().__setattr__(attr, val)\n        else:\n            setattr(self.__origin__, attr, val)\n\n    def __instancecheck__(self, obj):\n        return self.__subclasscheck__(type(obj))\n\n    def __subclasscheck__(self, cls):\n        raise TypeError(\"Subscripted generics cannot be used with\"\n                        \" class and instance checks\")\n\n    def __dir__(self):\n        return list(set(super().__dir__()\n                + [attr for attr in dir(self.__origin__) if not _is_dunder(attr)]))\n\n\n# Special typing constructs Union, Optional, Generic, Callable and Tuple\n# use three special attributes for internal bookkeeping of generic types:\n# * __parameters__ is a tuple of unique free type parameters of a generic\n#   type, for example, Dict[T, T].__parameters__ == (T,);\n# * __origin__ keeps a reference to a type that was subscripted,\n#   e.g., Union[T, int].__origin__ == Union, or the non-generic version of\n#   the type.\n# * __args__ is a tuple of all arguments used in subscripting,\n#   e.g., Dict[T, int].__args__ == (T, int).\n\n\nclass _GenericAlias(_BaseGenericAlias, _root=True):\n    # The type of parameterized generics.\n    #\n    # That is, for example, `type(List[int])` is `_GenericAlias`.\n    #\n    # Objects which are instances of this class include:\n    # * Parameterized container types, e.g. `Tuple[int]`, `List[int]`.\n    #  * Note that native container types, e.g. `tuple`, `list`, use\n    #    `types.GenericAlias` instead.\n    # * Parameterized classes:\n    #     T = TypeVar('T')\n    #     class C(Generic[T]): pass\n    #     # C[int] is a _GenericAlias\n    # * `Callable` aliases, generic `Callable` aliases, and\n    #   parameterized `Callable` aliases:\n    #     T = TypeVar('T')\n    #     # _CallableGenericAlias inherits from _GenericAlias.\n    #     A = Callable[[], None]  # _CallableGenericAlias\n    #     B = Callable[[T], None]  # _CallableGenericAlias\n    #     C = B[int]  # _CallableGenericAlias\n    # * Parameterized `Final`, `ClassVar` and `TypeGuard`:\n    #     # All _GenericAlias\n    #     Final[int]\n    #     ClassVar[float]\n    #     TypeVar[bool]\n\n    def __init__(self, origin, args, *, inst=True, name=None,\n                 _paramspec_tvars=False):\n        super().__init__(origin, inst=inst, name=name)\n        if not isinstance(args, tuple):\n            args = (args,)\n        self.__args__ = tuple(... if a is _TypingEllipsis else\n                              a for a in args)\n        self.__parameters__ = _collect_parameters(args)\n        self._paramspec_tvars = _paramspec_tvars\n        if not name:\n            self.__module__ = origin.__module__\n\n    def __eq__(self, other):\n        if not isinstance(other, _GenericAlias):\n            return NotImplemented\n        return (self.__origin__ == other.__origin__\n                and self.__args__ == other.__args__)\n\n    def __hash__(self):\n        return hash((self.__origin__, self.__args__))\n\n    def __or__(self, right):\n        return Union[self, right]\n\n    def __ror__(self, left):\n        return Union[left, self]\n\n    @_tp_cache\n    def __getitem__(self, args):\n        # Parameterizes an already-parameterized object.\n        #\n        # For example, we arrive here doing something like:\n        #   T1 = TypeVar('T1')\n        #   T2 = TypeVar('T2')\n        #   T3 = TypeVar('T3')\n        #   class A(Generic[T1]): pass\n        #   B = A[T2]  # B is a _GenericAlias\n        #   C = B[T3]  # Invokes _GenericAlias.__getitem__\n        #\n        # We also arrive here when parameterizing a generic `Callable` alias:\n        #   T = TypeVar('T')\n        #   C = Callable[[T], None]\n        #   C[int]  # Invokes _GenericAlias.__getitem__\n\n        if self.__origin__ in (Generic, Protocol):\n            # Can't subscript Generic[...] or Protocol[...].\n            raise TypeError(f\"Cannot subscript already-subscripted {self}\")\n        if not self.__parameters__:\n            raise TypeError(f\"{self} is not a generic class\")\n\n        # Preprocess `args`.\n        if not isinstance(args, tuple):\n            args = (args,)\n        args = tuple(_type_convert(p) for p in args)\n        args = _unpack_args(args)\n        new_args = self._determine_new_args(args)\n        r = self.copy_with(new_args)\n        return r\n\n    def _determine_new_args(self, args):\n        # Determines new __args__ for __getitem__.\n        #\n        # For example, suppose we had:\n        #   T1 = TypeVar('T1')\n        #   T2 = TypeVar('T2')\n        #   class A(Generic[T1, T2]): pass\n        #   T3 = TypeVar('T3')\n        #   B = A[int, T3]\n        #   C = B[str]\n        # `B.__args__` is `(int, T3)`, so `C.__args__` should be `(int, str)`.\n        # Unfortunately, this is harder than it looks, because if `T3` is\n        # anything more exotic than a plain `TypeVar`, we need to consider\n        # edge cases.\n\n        params = self.__parameters__\n        # In the example above, this would be {T3: str}\n        for param in params:\n            prepare = getattr(param, '__typing_prepare_subst__', None)\n            if prepare is not None:\n                args = prepare(self, args)\n        alen = len(args)\n        plen = len(params)\n        if alen != plen:\n            raise TypeError(f\"Too {'many' if alen > plen else 'few'} arguments for {self};\"\n                            f\" actual {alen}, expected {plen}\")\n        new_arg_by_param = dict(zip(params, args))\n        return tuple(self._make_substitution(self.__args__, new_arg_by_param))\n\n    def _make_substitution(self, args, new_arg_by_param):\n        \"\"\"Create a list of new type arguments.\"\"\"\n        new_args = []\n        for old_arg in args:\n            if isinstance(old_arg, type):\n                new_args.append(old_arg)\n                continue\n\n            substfunc = getattr(old_arg, '__typing_subst__', None)\n            if substfunc:\n                new_arg = substfunc(new_arg_by_param[old_arg])\n            else:\n                subparams = getattr(old_arg, '__parameters__', ())\n                if not subparams:\n                    new_arg = old_arg\n                else:\n                    subargs = []\n                    for x in subparams:\n                        if isinstance(x, TypeVarTuple):\n                            subargs.extend(new_arg_by_param[x])\n                        else:\n                            subargs.append(new_arg_by_param[x])\n                    new_arg = old_arg[tuple(subargs)]\n\n            if self.__origin__ == collections.abc.Callable and isinstance(new_arg, tuple):\n                # Consider the following `Callable`.\n                #   C = Callable[[int], str]\n                # Here, `C.__args__` should be (int, str) - NOT ([int], str).\n                # That means that if we had something like...\n                #   P = ParamSpec('P')\n                #   T = TypeVar('T')\n                #   C = Callable[P, T]\n                #   D = C[[int, str], float]\n                # ...we need to be careful; `new_args` should end up as\n                # `(int, str, float)` rather than `([int, str], float)`.\n                new_args.extend(new_arg)\n            elif _is_unpacked_typevartuple(old_arg):\n                # Consider the following `_GenericAlias`, `B`:\n                #   class A(Generic[*Ts]): ...\n                #   B = A[T, *Ts]\n                # If we then do:\n                #   B[float, int, str]\n                # The `new_arg` corresponding to `T` will be `float`, and the\n                # `new_arg` corresponding to `*Ts` will be `(int, str)`. We\n                # should join all these types together in a flat list\n                # `(float, int, str)` - so again, we should `extend`.\n                new_args.extend(new_arg)\n            elif isinstance(old_arg, tuple):\n                # Corner case:\n                #    P = ParamSpec('P')\n                #    T = TypeVar('T')\n                #    class Base(Generic[P]): ...\n                # Can be substituted like this:\n                #    X = Base[[int, T]]\n                # In this case, `old_arg` will be a tuple:\n                new_args.append(\n                    tuple(self._make_substitution(old_arg, new_arg_by_param)),\n                )\n            else:\n                new_args.append(new_arg)\n        return new_args\n\n    def copy_with(self, args):\n        return self.__class__(self.__origin__, args, name=self._name, inst=self._inst,\n                              _paramspec_tvars=self._paramspec_tvars)\n\n    def __repr__(self):\n        if self._name:\n            name = 'typing.' + self._name\n        else:\n            name = _type_repr(self.__origin__)\n        if self.__args__:\n            args = \", \".join([_type_repr(a) for a in self.__args__])\n        else:\n            # To ensure the repr is eval-able.\n            args = \"()\"\n        return f'{name}[{args}]'\n\n    def __reduce__(self):\n        if self._name:\n            origin = globals()[self._name]\n        else:\n            origin = self.__origin__\n        args = tuple(self.__args__)\n        if len(args) == 1 and not isinstance(args[0], tuple):\n            args, = args\n        return operator.getitem, (origin, args)\n\n    def __mro_entries__(self, bases):\n        if isinstance(self.__origin__, _SpecialForm):\n            raise TypeError(f\"Cannot subclass {self!r}\")\n\n        if self._name:  # generic version of an ABC or built-in class\n            return super().__mro_entries__(bases)\n        if self.__origin__ is Generic:\n            if Protocol in bases:\n                return ()\n            i = bases.index(self)\n            for b in bases[i+1:]:\n                if isinstance(b, _BaseGenericAlias) and b is not self:\n                    return ()\n        return (self.__origin__,)\n\n    def __iter__(self):\n        yield Unpack[self]\n\n\n# _nparams is the number of accepted parameters, e.g. 0 for Hashable,\n# 1 for List and 2 for Dict.  It may be -1 if variable number of\n# parameters are accepted (needs custom __getitem__).\n\nclass _SpecialGenericAlias(_NotIterable, _BaseGenericAlias, _root=True):\n    def __init__(self, origin, nparams, *, inst=True, name=None):\n        if name is None:\n            name = origin.__name__\n        super().__init__(origin, inst=inst, name=name)\n        self._nparams = nparams\n        if origin.__module__ == 'builtins':\n            self.__doc__ = f'A generic version of {origin.__qualname__}.'\n        else:\n            self.__doc__ = f'A generic version of {origin.__module__}.{origin.__qualname__}.'\n\n    @_tp_cache\n    def __getitem__(self, params):\n        if not isinstance(params, tuple):\n            params = (params,)\n        msg = \"Parameters to generic types must be types.\"\n        params = tuple(_type_check(p, msg) for p in params)\n        _check_generic(self, params, self._nparams)\n        return self.copy_with(params)\n\n    def copy_with(self, params):\n        return _GenericAlias(self.__origin__, params,\n                             name=self._name, inst=self._inst)\n\n    def __repr__(self):\n        return 'typing.' + self._name\n\n    def __subclasscheck__(self, cls):\n        if isinstance(cls, _SpecialGenericAlias):\n            return issubclass(cls.__origin__, self.__origin__)\n        if not isinstance(cls, _GenericAlias):\n            return issubclass(cls, self.__origin__)\n        return super().__subclasscheck__(cls)\n\n    def __reduce__(self):\n        return self._name\n\n    def __or__(self, right):\n        return Union[self, right]\n\n    def __ror__(self, left):\n        return Union[left, self]\n\nclass _CallableGenericAlias(_NotIterable, _GenericAlias, _root=True):\n    def __repr__(self):\n        assert self._name == 'Callable'\n        args = self.__args__\n        if len(args) == 2 and _is_param_expr(args[0]):\n            return super().__repr__()\n        return (f'typing.Callable'\n                f'[[{\", \".join([_type_repr(a) for a in args[:-1]])}], '\n                f'{_type_repr(args[-1])}]')\n\n    def __reduce__(self):\n        args = self.__args__\n        if not (len(args) == 2 and _is_param_expr(args[0])):\n            args = list(args[:-1]), args[-1]\n        return operator.getitem, (Callable, args)\n\n\nclass _CallableType(_SpecialGenericAlias, _root=True):\n    def copy_with(self, params):\n        return _CallableGenericAlias(self.__origin__, params,\n                                     name=self._name, inst=self._inst,\n                                     _paramspec_tvars=True)\n\n    def __getitem__(self, params):\n        if not isinstance(params, tuple) or len(params) != 2:\n            raise TypeError(\"Callable must be used as \"\n                            \"Callable[[arg, ...], result].\")\n        args, result = params\n        # This relaxes what args can be on purpose to allow things like\n        # PEP 612 ParamSpec.  Responsibility for whether a user is using\n        # Callable[...] properly is deferred to static type checkers.\n        if isinstance(args, list):\n            params = (tuple(args), result)\n        else:\n            params = (args, result)\n        return self.__getitem_inner__(params)\n\n    @_tp_cache\n    def __getitem_inner__(self, params):\n        args, result = params\n        msg = \"Callable[args, result]: result must be a type.\"\n        result = _type_check(result, msg)\n        if args is Ellipsis:\n            return self.copy_with((_TypingEllipsis, result))\n        if not isinstance(args, tuple):\n            args = (args,)\n        args = tuple(_type_convert(arg) for arg in args)\n        params = args + (result,)\n        return self.copy_with(params)\n\n\nclass _TupleType(_SpecialGenericAlias, _root=True):\n    @_tp_cache\n    def __getitem__(self, params):\n        if not isinstance(params, tuple):\n            params = (params,)\n        if len(params) >= 2 and params[-1] is ...:\n            msg = \"Tuple[t, ...]: t must be a type.\"\n            params = tuple(_type_check(p, msg) for p in params[:-1])\n            return self.copy_with((*params, _TypingEllipsis))\n        msg = \"Tuple[t0, t1, ...]: each t must be a type.\"\n        params = tuple(_type_check(p, msg) for p in params)\n        return self.copy_with(params)\n\n\nclass _UnionGenericAlias(_NotIterable, _GenericAlias, _root=True):\n    def copy_with(self, params):\n        return Union[params]\n\n    def __eq__(self, other):\n        if not isinstance(other, (_UnionGenericAlias, types.UnionType)):\n            return NotImplemented\n        return set(self.__args__) == set(other.__args__)\n\n    def __hash__(self):\n        return hash(frozenset(self.__args__))\n\n    def __repr__(self):\n        args = self.__args__\n        if len(args) == 2:\n            if args[0] is type(None):\n                return f'typing.Optional[{_type_repr(args[1])}]'\n            elif args[1] is type(None):\n                return f'typing.Optional[{_type_repr(args[0])}]'\n        return super().__repr__()\n\n    def __instancecheck__(self, obj):\n        return self.__subclasscheck__(type(obj))\n\n    def __subclasscheck__(self, cls):\n        for arg in self.__args__:\n            if issubclass(cls, arg):\n                return True\n\n    def __reduce__(self):\n        func, (origin, args) = super().__reduce__()\n        return func, (Union, args)\n\n\ndef _value_and_type_iter(parameters):\n    return ((p, type(p)) for p in parameters)\n\n\nclass _LiteralGenericAlias(_GenericAlias, _root=True):\n    def __eq__(self, other):\n        if not isinstance(other, _LiteralGenericAlias):\n            return NotImplemented\n\n        return set(_value_and_type_iter(self.__args__)) == set(_value_and_type_iter(other.__args__))\n\n    def __hash__(self):\n        return hash(frozenset(_value_and_type_iter(self.__args__)))\n\n\nclass _ConcatenateGenericAlias(_GenericAlias, _root=True):\n    def copy_with(self, params):\n        if isinstance(params[-1], (list, tuple)):\n            return (*params[:-1], *params[-1])\n        if isinstance(params[-1], _ConcatenateGenericAlias):\n            params = (*params[:-1], *params[-1].__args__)\n        return super().copy_with(params)\n\n\n@_SpecialForm\ndef Unpack(self, parameters):\n    \"\"\"Type unpack operator.\n\n    The type unpack operator takes the child types from some container type,\n    such as `tuple[int, str]` or a `TypeVarTuple`, and 'pulls them out'.\n\n    For example::\n\n        # For some generic class `Foo`:\n        Foo[Unpack[tuple[int, str]]]  # Equivalent to Foo[int, str]\n\n        Ts = TypeVarTuple('Ts')\n        # Specifies that `Bar` is generic in an arbitrary number of types.\n        # (Think of `Ts` as a tuple of an arbitrary number of individual\n        #  `TypeVar`s, which the `Unpack` is 'pulling out' directly into the\n        #  `Generic[]`.)\n        class Bar(Generic[Unpack[Ts]]): ...\n        Bar[int]  # Valid\n        Bar[int, str]  # Also valid\n\n    From Python 3.11, this can also be done using the `*` operator::\n\n        Foo[*tuple[int, str]]\n        class Bar(Generic[*Ts]): ...\n\n    Note that there is only some runtime checking of this operator. Not\n    everything the runtime allows may be accepted by static type checkers.\n\n    For more information, see PEP 646.\n    \"\"\"\n    item = _type_check(parameters, f'{self} accepts only single type.')\n    return _UnpackGenericAlias(origin=self, args=(item,))\n\n\nclass _UnpackGenericAlias(_GenericAlias, _root=True):\n    def __repr__(self):\n        # `Unpack` only takes one argument, so __args__ should contain only\n        # a single item.\n        return '*' + repr(self.__args__[0])\n\n    def __getitem__(self, args):\n        if self.__typing_is_unpacked_typevartuple__:\n            return args\n        return super().__getitem__(args)\n\n    @property\n    def __typing_unpacked_tuple_args__(self):\n        assert self.__origin__ is Unpack\n        assert len(self.__args__) == 1\n        arg, = self.__args__\n        if isinstance(arg, _GenericAlias):\n            assert arg.__origin__ is tuple\n            return arg.__args__\n        return None\n\n    @property\n    def __typing_is_unpacked_typevartuple__(self):\n        assert self.__origin__ is Unpack\n        assert len(self.__args__) == 1\n        return isinstance(self.__args__[0], TypeVarTuple)\n\n\nclass Generic:\n    \"\"\"Abstract base class for generic types.\n\n    A generic type is typically declared by inheriting from\n    this class parameterized with one or more type variables.\n    For example, a generic mapping type might be defined as::\n\n      class Mapping(Generic[KT, VT]):\n          def __getitem__(self, key: KT) -> VT:\n              ...\n          # Etc.\n\n    This class can then be used as follows::\n\n      def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:\n          try:\n              return mapping[key]\n          except KeyError:\n              return default\n    \"\"\"\n    __slots__ = ()\n    _is_protocol = False\n\n    @_tp_cache\n    def __class_getitem__(cls, params):\n        \"\"\"Parameterizes a generic class.\n\n        At least, parameterizing a generic class is the *main* thing this method\n        does. For example, for some generic class `Foo`, this is called when we\n        do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n\n        However, note that this method is also called when defining generic\n        classes in the first place with `class Foo(Generic[T]): ...`.\n        \"\"\"\n        if not isinstance(params, tuple):\n            params = (params,)\n\n        params = tuple(_type_convert(p) for p in params)\n        if cls in (Generic, Protocol):\n            # Generic and Protocol can only be subscripted with unique type variables.\n            if not params:\n                raise TypeError(\n                    f\"Parameter list to {cls.__qualname__}[...] cannot be empty\"\n                )\n            if not all(_is_typevar_like(p) for p in params):\n                raise TypeError(\n                    f\"Parameters to {cls.__name__}[...] must all be type variables \"\n                    f\"or parameter specification variables.\")\n            if len(set(params)) != len(params):\n                raise TypeError(\n                    f\"Parameters to {cls.__name__}[...] must all be unique\")\n        else:\n            # Subscripting a regular Generic subclass.\n            for param in cls.__parameters__:\n                prepare = getattr(param, '__typing_prepare_subst__', None)\n                if prepare is not None:\n                    params = prepare(cls, params)\n            _check_generic(cls, params, len(cls.__parameters__))\n\n            new_args = []\n            for param, new_arg in zip(cls.__parameters__, params):\n                if isinstance(param, TypeVarTuple):\n                    new_args.extend(new_arg)\n                else:\n                    new_args.append(new_arg)\n            params = tuple(new_args)\n\n        return _GenericAlias(cls, params,\n                             _paramspec_tvars=True)\n\n    def __init_subclass__(cls, *args, **kwargs):\n        super().__init_subclass__(*args, **kwargs)\n        tvars = []\n        if '__orig_bases__' in cls.__dict__:\n            error = Generic in cls.__orig_bases__\n        else:\n            error = (Generic in cls.__bases__ and\n                        cls.__name__ != 'Protocol' and\n                        type(cls) != _TypedDictMeta)\n        if error:\n            raise TypeError(\"Cannot inherit from plain Generic\")\n        if '__orig_bases__' in cls.__dict__:\n            tvars = _collect_parameters(cls.__orig_bases__)\n            # Look for Generic[T1, ..., Tn].\n            # If found, tvars must be a subset of it.\n            # If not found, tvars is it.\n            # Also check for and reject plain Generic,\n            # and reject multiple Generic[...].\n            gvars = None\n            for base in cls.__orig_bases__:\n                if (isinstance(base, _GenericAlias) and\n                        base.__origin__ is Generic):\n                    if gvars is not None:\n                        raise TypeError(\n                            \"Cannot inherit from Generic[...] multiple times.\")\n                    gvars = base.__parameters__\n            if gvars is not None:\n                tvarset = set(tvars)\n                gvarset = set(gvars)\n                if not tvarset <= gvarset:\n                    s_vars = ', '.join(str(t) for t in tvars if t not in gvarset)\n                    s_args = ', '.join(str(g) for g in gvars)\n                    raise TypeError(f\"Some type variables ({s_vars}) are\"\n                                    f\" not listed in Generic[{s_args}]\")\n                tvars = gvars\n        cls.__parameters__ = tuple(tvars)\n\n\nclass _TypingEllipsis:\n    \"\"\"Internal placeholder for ... (ellipsis).\"\"\"\n\n\n_TYPING_INTERNALS = ['__parameters__', '__orig_bases__',  '__orig_class__',\n                     '_is_protocol', '_is_runtime_protocol', '__final__']\n\n_SPECIAL_NAMES = ['__abstractmethods__', '__annotations__', '__dict__', '__doc__',\n                  '__init__', '__module__', '__new__', '__slots__',\n                  '__subclasshook__', '__weakref__', '__class_getitem__']\n\n# These special attributes will be not collected as protocol members.\nEXCLUDED_ATTRIBUTES = _TYPING_INTERNALS + _SPECIAL_NAMES + ['_MutableMapping__marker']\n\n\ndef _get_protocol_attrs(cls):\n    \"\"\"Collect protocol members from a protocol class objects.\n\n    This includes names actually defined in the class dictionary, as well\n    as names that appear in annotations. Special names (above) are skipped.\n    \"\"\"\n    attrs = set()\n    for base in cls.__mro__[:-1]:  # without object\n        if base.__name__ in ('Protocol', 'Generic'):\n            continue\n        annotations = getattr(base, '__annotations__', {})\n        for attr in list(base.__dict__.keys()) + list(annotations.keys()):\n            if not attr.startswith('_abc_') and attr not in EXCLUDED_ATTRIBUTES:\n                attrs.add(attr)\n    return attrs\n\n\ndef _is_callable_members_only(cls):\n    # PEP 544 prohibits using issubclass() with protocols that have non-method members.\n    return all(callable(getattr(cls, attr, None)) for attr in _get_protocol_attrs(cls))\n\n\ndef _no_init_or_replace_init(self, *args, **kwargs):\n    cls = type(self)\n\n    if cls._is_protocol:\n        raise TypeError('Protocols cannot be instantiated')\n\n    # Already using a custom `__init__`. No need to calculate correct\n    # `__init__` to call. This can lead to RecursionError. See bpo-45121.\n    if cls.__init__ is not _no_init_or_replace_init:\n        return\n\n    # Initially, `__init__` of a protocol subclass is set to `_no_init_or_replace_init`.\n    # The first instantiation of the subclass will call `_no_init_or_replace_init` which\n    # searches for a proper new `__init__` in the MRO. The new `__init__`\n    # replaces the subclass' old `__init__` (ie `_no_init_or_replace_init`). Subsequent\n    # instantiation of the protocol subclass will thus use the new\n    # `__init__` and no longer call `_no_init_or_replace_init`.\n    for base in cls.__mro__:\n        init = base.__dict__.get('__init__', _no_init_or_replace_init)\n        if init is not _no_init_or_replace_init:\n            cls.__init__ = init\n            break\n    else:\n        # should not happen\n        cls.__init__ = object.__init__\n\n    cls.__init__(self, *args, **kwargs)\n\n\ndef _caller(depth=1, default='__main__'):\n    try:\n        return sys._getframe(depth + 1).f_globals.get('__name__', default)\n    except (AttributeError, ValueError):  # For platforms without _getframe()\n        return None\n\n\ndef _allow_reckless_class_checks(depth=3):\n    \"\"\"Allow instance and class checks for special stdlib modules.\n\n    The abc and functools modules indiscriminately call isinstance() and\n    issubclass() on the whole MRO of a user class, which may contain protocols.\n    \"\"\"\n    return _caller(depth) in {'abc', 'functools', None}\n\n\n_PROTO_ALLOWLIST = {\n    'collections.abc': [\n        'Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',\n        'Hashable', 'Sized', 'Container', 'Collection', 'Reversible',\n    ],\n    'contextlib': ['AbstractContextManager', 'AbstractAsyncContextManager'],\n}\n\n\nclass _ProtocolMeta(ABCMeta):\n    # This metaclass is really unfortunate and exists only because of\n    # the lack of __instancehook__.\n    def __instancecheck__(cls, instance):\n        # We need this method for situations where attributes are\n        # assigned in __init__.\n        if (\n            getattr(cls, '_is_protocol', False) and\n            not getattr(cls, '_is_runtime_protocol', False) and\n            not _allow_reckless_class_checks(depth=2)\n        ):\n            raise TypeError(\"Instance and class checks can only be used with\"\n                            \" @runtime_checkable protocols\")\n\n        if ((not getattr(cls, '_is_protocol', False) or\n                _is_callable_members_only(cls)) and\n                issubclass(instance.__class__, cls)):\n            return True\n        if cls._is_protocol:\n            if all(hasattr(instance, attr) and\n                    # All *methods* can be blocked by setting them to None.\n                    (not callable(getattr(cls, attr, None)) or\n                     getattr(instance, attr) is not None)\n                    for attr in _get_protocol_attrs(cls)):\n                return True\n        return super().__instancecheck__(instance)\n\n\nclass Protocol(Generic, metaclass=_ProtocolMeta):\n    \"\"\"Base class for protocol classes.\n\n    Protocol classes are defined as::\n\n        class Proto(Protocol):\n            def meth(self) -> int:\n                ...\n\n    Such classes are primarily used with static type checkers that recognize\n    structural subtyping (static duck-typing).\n\n    For example::\n\n        class C:\n            def meth(self) -> int:\n                return 0\n\n        def func(x: Proto) -> int:\n            return x.meth()\n\n        func(C())  # Passes static type check\n\n    See PEP 544 for details. Protocol classes decorated with\n    @typing.runtime_checkable act as simple-minded runtime protocols that check\n    only the presence of given attributes, ignoring their type signatures.\n    Protocol classes can be generic, they are defined as::\n\n        class GenProto(Protocol[T]):\n            def meth(self) -> T:\n                ...\n    \"\"\"\n\n    __slots__ = ()\n    _is_protocol = True\n    _is_runtime_protocol = False\n\n    def __init_subclass__(cls, *args, **kwargs):\n        super().__init_subclass__(*args, **kwargs)\n\n        # Determine if this is a protocol or a concrete subclass.\n        if not cls.__dict__.get('_is_protocol', False):\n            cls._is_protocol = any(b is Protocol for b in cls.__bases__)\n\n        # Set (or override) the protocol subclass hook.\n        def _proto_hook(other):\n            if not cls.__dict__.get('_is_protocol', False):\n                return NotImplemented\n\n            # First, perform various sanity checks.\n            if not getattr(cls, '_is_runtime_protocol', False):\n                if _allow_reckless_class_checks():\n                    return NotImplemented\n                raise TypeError(\"Instance and class checks can only be used with\"\n                                \" @runtime_checkable protocols\")\n            if not _is_callable_members_only(cls):\n                if _allow_reckless_class_checks():\n                    return NotImplemented\n                raise TypeError(\"Protocols with non-method members\"\n                                \" don't support issubclass()\")\n            if not isinstance(other, type):\n                # Same error message as for issubclass(1, int).\n                raise TypeError('issubclass() arg 1 must be a class')\n\n            # Second, perform the actual structural compatibility check.\n            for attr in _get_protocol_attrs(cls):\n                for base in other.__mro__:\n                    # Check if the members appears in the class dictionary...\n                    if attr in base.__dict__:\n                        if base.__dict__[attr] is None:\n                            return NotImplemented\n                        break\n\n                    # ...or in annotations, if it is a sub-protocol.\n                    annotations = getattr(base, '__annotations__', {})\n                    if (isinstance(annotations, collections.abc.Mapping) and\n                            attr in annotations and\n                            issubclass(other, Generic) and other._is_protocol):\n                        break\n                else:\n                    return NotImplemented\n            return True\n\n        if '__subclasshook__' not in cls.__dict__:\n            cls.__subclasshook__ = _proto_hook\n\n        # We have nothing more to do for non-protocols...\n        if not cls._is_protocol:\n            return\n\n        # ... otherwise check consistency of bases, and prohibit instantiation.\n        for base in cls.__bases__:\n            if not (base in (object, Generic) or\n                    base.__module__ in _PROTO_ALLOWLIST and\n                    base.__name__ in _PROTO_ALLOWLIST[base.__module__] or\n                    issubclass(base, Generic) and base._is_protocol):\n                raise TypeError('Protocols can only inherit from other'\n                                ' protocols, got %r' % base)\n        if cls.__init__ is Protocol.__init__:\n            cls.__init__ = _no_init_or_replace_init\n\n\nclass _AnnotatedAlias(_NotIterable, _GenericAlias, _root=True):\n    \"\"\"Runtime representation of an annotated type.\n\n    At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'\n    with extra annotations. The alias behaves like a normal typing alias.\n    Instantiating is the same as instantiating the underlying type; binding\n    it to types is also the same.\n\n    The metadata itself is stored in a '__metadata__' attribute as a tuple.\n    \"\"\"\n\n    def __init__(self, origin, metadata):\n        if isinstance(origin, _AnnotatedAlias):\n            metadata = origin.__metadata__ + metadata\n            origin = origin.__origin__\n        super().__init__(origin, origin)\n        self.__metadata__ = metadata\n\n    def copy_with(self, params):\n        assert len(params) == 1\n        new_type = params[0]\n        return _AnnotatedAlias(new_type, self.__metadata__)\n\n    def __repr__(self):\n        return \"typing.Annotated[{}, {}]\".format(\n            _type_repr(self.__origin__),\n            \", \".join(repr(a) for a in self.__metadata__)\n        )\n\n    def __reduce__(self):\n        return operator.getitem, (\n            Annotated, (self.__origin__,) + self.__metadata__\n        )\n\n    def __eq__(self, other):\n        if not isinstance(other, _AnnotatedAlias):\n            return NotImplemented\n        return (self.__origin__ == other.__origin__\n                and self.__metadata__ == other.__metadata__)\n\n    def __hash__(self):\n        return hash((self.__origin__, self.__metadata__))\n\n    def __getattr__(self, attr):\n        if attr in {'__name__', '__qualname__'}:\n            return 'Annotated'\n        return super().__getattr__(attr)\n\n\nclass Annotated:\n    \"\"\"Add context-specific metadata to a type.\n\n    Example: Annotated[int, runtime_check.Unsigned] indicates to the\n    hypothetical runtime_check module that this type is an unsigned int.\n    Every other consumer of this type can ignore this metadata and treat\n    this type as int.\n\n    The first argument to Annotated must be a valid type.\n\n    Details:\n\n    - It's an error to call `Annotated` with less than two arguments.\n    - Access the metadata via the ``__metadata__`` attribute::\n\n        assert Annotated[int, '$'].__metadata__ == ('$',)\n\n    - Nested Annotated types are flattened::\n\n        assert Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]\n\n    - Instantiating an annotated type is equivalent to instantiating the\n    underlying type::\n\n        assert Annotated[C, Ann1](5) == C(5)\n\n    - Annotated can be used as a generic type alias::\n\n        Optimized: TypeAlias = Annotated[T, runtime.Optimize()]\n        assert Optimized[int] == Annotated[int, runtime.Optimize()]\n\n        OptimizedList: TypeAlias = Annotated[list[T], runtime.Optimize()]\n        assert OptimizedList[int] == Annotated[list[int], runtime.Optimize()]\n\n    - Annotated cannot be used with an unpacked TypeVarTuple::\n\n        Variadic: TypeAlias = Annotated[*Ts, Ann1]  # NOT valid\n\n      This would be equivalent to::\n\n        Annotated[T1, T2, T3, ..., Ann1]\n\n      where T1, T2 etc. are TypeVars, which would be invalid, because\n      only one type should be passed to Annotated.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __new__(cls, *args, **kwargs):\n        raise TypeError(\"Type Annotated cannot be instantiated.\")\n\n    @_tp_cache\n    def __class_getitem__(cls, params):\n        if not isinstance(params, tuple) or len(params) < 2:\n            raise TypeError(\"Annotated[...] should be used \"\n                            \"with at least two arguments (a type and an \"\n                            \"annotation).\")\n        if _is_unpacked_typevartuple(params[0]):\n            raise TypeError(\"Annotated[...] should not be used with an \"\n                            \"unpacked TypeVarTuple\")\n        msg = \"Annotated[t, ...]: t must be a type.\"\n        origin = _type_check(params[0], msg, allow_special_forms=True)\n        metadata = tuple(params[1:])\n        return _AnnotatedAlias(origin, metadata)\n\n    def __init_subclass__(cls, *args, **kwargs):\n        raise TypeError(\n            \"Cannot subclass {}.Annotated\".format(cls.__module__)\n        )\n\n\ndef runtime_checkable(cls):\n    \"\"\"Mark a protocol class as a runtime protocol.\n\n    Such protocol can be used with isinstance() and issubclass().\n    Raise TypeError if applied to a non-protocol class.\n    This allows a simple-minded structural check very similar to\n    one trick ponies in collections.abc such as Iterable.\n\n    For example::\n\n        @runtime_checkable\n        class Closable(Protocol):\n            def close(self): ...\n\n        assert isinstance(open('/some/file'), Closable)\n\n    Warning: this will check only the presence of the required methods,\n    not their type signatures!\n    \"\"\"\n    if not issubclass(cls, Generic) or not cls._is_protocol:\n        raise TypeError('@runtime_checkable can be only applied to protocol classes,'\n                        ' got %r' % cls)\n    cls._is_runtime_protocol = True\n    return cls\n\n\ndef cast(typ, val):\n    \"\"\"Cast a value to a type.\n\n    This returns the value unchanged.  To the type checker this\n    signals that the return value has the designated type, but at\n    runtime we intentionally don't check anything (we want this\n    to be as fast as possible).\n    \"\"\"\n    return val\n\n\ndef assert_type(val, typ, /):\n    \"\"\"Ask a static type checker to confirm that the value is of the given type.\n\n    At runtime this does nothing: it returns the first argument unchanged with no\n    checks or side effects, no matter the actual type of the argument.\n\n    When a static type checker encounters a call to assert_type(), it\n    emits an error if the value is not of the specified type::\n\n        def greet(name: str) -> None:\n            assert_type(name, str)  # OK\n            assert_type(name, int)  # type checker error\n    \"\"\"\n    return val\n\n\n_allowed_types = (types.FunctionType, types.BuiltinFunctionType,\n                  types.MethodType, types.ModuleType,\n                  WrapperDescriptorType, MethodWrapperType, MethodDescriptorType)\n\n\ndef get_type_hints(obj, globalns=None, localns=None, include_extras=False):\n    \"\"\"Return type hints for an object.\n\n    This is often the same as obj.__annotations__, but it handles\n    forward references encoded as string literals and recursively replaces all\n    'Annotated[T, ...]' with 'T' (unless 'include_extras=True').\n\n    The argument may be a module, class, method, or function. The annotations\n    are returned as a dictionary. For classes, annotations include also\n    inherited members.\n\n    TypeError is raised if the argument is not of a type that can contain\n    annotations, and an empty dictionary is returned if no annotations are\n    present.\n\n    BEWARE -- the behavior of globalns and localns is counterintuitive\n    (unless you are familiar with how eval() and exec() work).  The\n    search order is locals first, then globals.\n\n    - If no dict arguments are passed, an attempt is made to use the\n      globals from obj (or the respective module's globals for classes),\n      and these are also used as the locals.  If the object does not appear\n      to have globals, an empty dictionary is used.  For classes, the search\n      order is globals first then locals.\n\n    - If one dict argument is passed, it is used for both globals and\n      locals.\n\n    - If two dict arguments are passed, they specify globals and\n      locals, respectively.\n    \"\"\"\n    if getattr(obj, '__no_type_check__', None):\n        return {}\n    # Classes require a special treatment.\n    if isinstance(obj, type):\n        hints = {}\n        for base in reversed(obj.__mro__):\n            if globalns is None:\n                base_globals = getattr(sys.modules.get(base.__module__, None), '__dict__', {})\n            else:\n                base_globals = globalns\n            ann = base.__dict__.get('__annotations__', {})\n            if isinstance(ann, types.GetSetDescriptorType):\n                ann = {}\n            base_locals = dict(vars(base)) if localns is None else localns\n            if localns is None and globalns is None:\n                # This is surprising, but required.  Before Python 3.10,\n                # get_type_hints only evaluated the globalns of\n                # a class.  To maintain backwards compatibility, we reverse\n                # the globalns and localns order so that eval() looks into\n                # *base_globals* first rather than *base_locals*.\n                # This only affects ForwardRefs.\n                base_globals, base_locals = base_locals, base_globals\n            for name, value in ann.items():\n                if value is None:\n                    value = type(None)\n                if isinstance(value, str):\n                    value = ForwardRef(value, is_argument=False, is_class=True)\n                value = _eval_type(value, base_globals, base_locals)\n                hints[name] = value\n        return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}\n\n    if globalns is None:\n        if isinstance(obj, types.ModuleType):\n            globalns = obj.__dict__\n        else:\n            nsobj = obj\n            # Find globalns for the unwrapped object.\n            while hasattr(nsobj, '__wrapped__'):\n                nsobj = nsobj.__wrapped__\n            globalns = getattr(nsobj, '__globals__', {})\n        if localns is None:\n            localns = globalns\n    elif localns is None:\n        localns = globalns\n    hints = getattr(obj, '__annotations__', None)\n    if hints is None:\n        # Return empty annotations for something that _could_ have them.\n        if isinstance(obj, _allowed_types):\n            return {}\n        else:\n            raise TypeError('{!r} is not a module, class, method, '\n                            'or function.'.format(obj))\n    hints = dict(hints)\n    for name, value in hints.items():\n        if value is None:\n            value = type(None)\n        if isinstance(value, str):\n            # class-level forward refs were handled above, this must be either\n            # a module-level annotation or a function argument annotation\n            value = ForwardRef(\n                value,\n                is_argument=not isinstance(obj, types.ModuleType),\n                is_class=False,\n            )\n        hints[name] = _eval_type(value, globalns, localns)\n    return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}\n\n\ndef _strip_annotations(t):\n    \"\"\"Strip the annotations from a given type.\"\"\"\n    if isinstance(t, _AnnotatedAlias):\n        return _strip_annotations(t.__origin__)\n    if hasattr(t, \"__origin__\") and t.__origin__ in (Required, NotRequired):\n        return _strip_annotations(t.__args__[0])\n    if isinstance(t, _GenericAlias):\n        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n        if stripped_args == t.__args__:\n            return t\n        return t.copy_with(stripped_args)\n    if isinstance(t, GenericAlias):\n        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n        if stripped_args == t.__args__:\n            return t\n        return GenericAlias(t.__origin__, stripped_args)\n    if isinstance(t, types.UnionType):\n        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n        if stripped_args == t.__args__:\n            return t\n        return functools.reduce(operator.or_, stripped_args)\n\n    return t\n\n\ndef get_origin(tp):\n    \"\"\"Get the unsubscripted version of a type.\n\n    This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar,\n    Annotated, and others. Return None for unsupported types.\n\n    Examples::\n\n        assert get_origin(Literal[42]) is Literal\n        assert get_origin(int) is None\n        assert get_origin(ClassVar[int]) is ClassVar\n        assert get_origin(Generic) is Generic\n        assert get_origin(Generic[T]) is Generic\n        assert get_origin(Union[T, int]) is Union\n        assert get_origin(List[Tuple[T, T]][int]) is list\n        assert get_origin(P.args) is P\n    \"\"\"\n    if isinstance(tp, _AnnotatedAlias):\n        return Annotated\n    if isinstance(tp, (_BaseGenericAlias, GenericAlias,\n                       ParamSpecArgs, ParamSpecKwargs)):\n        return tp.__origin__\n    if tp is Generic:\n        return Generic\n    if isinstance(tp, types.UnionType):\n        return types.UnionType\n    return None\n\n\ndef get_args(tp):\n    \"\"\"Get type arguments with all substitutions performed.\n\n    For unions, basic simplifications used by Union constructor are performed.\n\n    Examples::\n\n        assert get_args(Dict[str, int]) == (str, int)\n        assert get_args(int) == ()\n        assert get_args(Union[int, Union[T, int], str][int]) == (int, str)\n        assert get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])\n        assert get_args(Callable[[], T][int]) == ([], int)\n    \"\"\"\n    if isinstance(tp, _AnnotatedAlias):\n        return (tp.__origin__,) + tp.__metadata__\n    if isinstance(tp, (_GenericAlias, GenericAlias)):\n        res = tp.__args__\n        if _should_unflatten_callable_args(tp, res):\n            res = (list(res[:-1]), res[-1])\n        return res\n    if isinstance(tp, types.UnionType):\n        return tp.__args__\n    return ()\n\n\ndef is_typeddict(tp):\n    \"\"\"Check if an annotation is a TypedDict class.\n\n    For example::\n\n        class Film(TypedDict):\n            title: str\n            year: int\n\n        is_typeddict(Film)              # => True\n        is_typeddict(Union[list, str])  # => False\n    \"\"\"\n    return isinstance(tp, _TypedDictMeta)\n\n\n_ASSERT_NEVER_REPR_MAX_LENGTH = 100\n\n\ndef assert_never(arg: Never, /) -> Never:\n    \"\"\"Statically assert that a line of code is unreachable.\n\n    Example::\n\n        def int_or_str(arg: int | str) -> None:\n            match arg:\n                case int():\n                    print(\"It's an int\")\n                case str():\n                    print(\"It's a str\")\n                case _:\n                    assert_never(arg)\n\n    If a type checker finds that a call to assert_never() is\n    reachable, it will emit an error.\n\n    At runtime, this throws an exception when called.\n    \"\"\"\n    value = repr(arg)\n    if len(value) > _ASSERT_NEVER_REPR_MAX_LENGTH:\n        value = value[:_ASSERT_NEVER_REPR_MAX_LENGTH] + '...'\n    raise AssertionError(f\"Expected code to be unreachable, but got: {value}\")\n\n\ndef no_type_check(arg):\n    \"\"\"Decorator to indicate that annotations are not type hints.\n\n    The argument must be a class or function; if it is a class, it\n    applies recursively to all methods and classes defined in that class\n    (but not to methods defined in its superclasses or subclasses).\n\n    This mutates the function(s) or class(es) in place.\n    \"\"\"\n    if isinstance(arg, type):\n        for key in dir(arg):\n            obj = getattr(arg, key)\n            if (\n                not hasattr(obj, '__qualname__')\n                or obj.__qualname__ != f'{arg.__qualname__}.{obj.__name__}'\n                or getattr(obj, '__module__', None) != arg.__module__\n            ):\n                # We only modify objects that are defined in this type directly.\n                # If classes / methods are nested in multiple layers,\n                # we will modify them when processing their direct holders.\n                continue\n            # Instance, class, and static methods:\n            if isinstance(obj, types.FunctionType):\n                obj.__no_type_check__ = True\n            if isinstance(obj, types.MethodType):\n                obj.__func__.__no_type_check__ = True\n            # Nested types:\n            if isinstance(obj, type):\n                no_type_check(obj)\n    try:\n        arg.__no_type_check__ = True\n    except TypeError:  # built-in classes\n        pass\n    return arg\n\n\ndef no_type_check_decorator(decorator):\n    \"\"\"Decorator to give another decorator the @no_type_check effect.\n\n    This wraps the decorator with something that wraps the decorated\n    function in @no_type_check.\n    \"\"\"\n    @functools.wraps(decorator)\n    def wrapped_decorator(*args, **kwds):\n        func = decorator(*args, **kwds)\n        func = no_type_check(func)\n        return func\n\n    return wrapped_decorator\n\n\ndef _overload_dummy(*args, **kwds):\n    \"\"\"Helper for @overload to raise when called.\"\"\"\n    raise NotImplementedError(\n        \"You should not call an overloaded function. \"\n        \"A series of @overload-decorated functions \"\n        \"outside a stub module should always be followed \"\n        \"by an implementation that is not @overload-ed.\")\n\n\n# {module: {qualname: {firstlineno: func}}}\n_overload_registry = defaultdict(functools.partial(defaultdict, dict))\n\n\ndef overload(func):\n    \"\"\"Decorator for overloaded functions/methods.\n\n    In a stub file, place two or more stub definitions for the same\n    function in a row, each decorated with @overload.\n\n    For example::\n\n        @overload\n        def utf8(value: None) -> None: ...\n        @overload\n        def utf8(value: bytes) -> bytes: ...\n        @overload\n        def utf8(value: str) -> bytes: ...\n\n    In a non-stub file (i.e. a regular .py file), do the same but\n    follow it with an implementation.  The implementation should *not*\n    be decorated with @overload::\n\n        @overload\n        def utf8(value: None) -> None: ...\n        @overload\n        def utf8(value: bytes) -> bytes: ...\n        @overload\n        def utf8(value: str) -> bytes: ...\n        def utf8(value):\n            ...  # implementation goes here\n\n    The overloads for a function can be retrieved at runtime using the\n    get_overloads() function.\n    \"\"\"\n    # classmethod and staticmethod\n    f = getattr(func, \"__func__\", func)\n    try:\n        _overload_registry[f.__module__][f.__qualname__][f.__code__.co_firstlineno] = func\n    except AttributeError:\n        # Not a normal function; ignore.\n        pass\n    return _overload_dummy\n\n\ndef get_overloads(func):\n    \"\"\"Return all defined overloads for *func* as a sequence.\"\"\"\n    # classmethod and staticmethod\n    f = getattr(func, \"__func__\", func)\n    if f.__module__ not in _overload_registry:\n        return []\n    mod_dict = _overload_registry[f.__module__]\n    if f.__qualname__ not in mod_dict:\n        return []\n    return list(mod_dict[f.__qualname__].values())\n\n\ndef clear_overloads():\n    \"\"\"Clear all overloads in the registry.\"\"\"\n    _overload_registry.clear()\n\n\ndef final(f):\n    \"\"\"Decorator to indicate final methods and final classes.\n\n    Use this decorator to indicate to type checkers that the decorated\n    method cannot be overridden, and decorated class cannot be subclassed.\n\n    For example::\n\n        class Base:\n            @final\n            def done(self) -> None:\n                ...\n        class Sub(Base):\n            def done(self) -> None:  # Error reported by type checker\n                ...\n\n        @final\n        class Leaf:\n            ...\n        class Other(Leaf):  # Error reported by type checker\n            ...\n\n    There is no runtime checking of these properties. The decorator\n    attempts to set the ``__final__`` attribute to ``True`` on the decorated\n    object to allow runtime introspection.\n    \"\"\"\n    try:\n        f.__final__ = True\n    except (AttributeError, TypeError):\n        # Skip the attribute silently if it is not writable.\n        # AttributeError happens if the object has __slots__ or a\n        # read-only property, TypeError if it's a builtin class.\n        pass\n    return f\n\n\n# Some unconstrained type variables.  These are used by the container types.\n# (These are not for export.)\nT = TypeVar('T')  # Any type.\nKT = TypeVar('KT')  # Key type.\nVT = TypeVar('VT')  # Value type.\nT_co = TypeVar('T_co', covariant=True)  # Any type covariant containers.\nV_co = TypeVar('V_co', covariant=True)  # Any type covariant containers.\nVT_co = TypeVar('VT_co', covariant=True)  # Value type covariant containers.\nT_contra = TypeVar('T_contra', contravariant=True)  # Ditto contravariant.\n# Internal type variable used for Type[].\nCT_co = TypeVar('CT_co', covariant=True, bound=type)\n\n# A useful type variable with constraints.  This represents string types.\n# (This one *is* for export!)\nAnyStr = TypeVar('AnyStr', bytes, str)\n\n\n# Various ABCs mimicking those in collections.abc.\n_alias = _SpecialGenericAlias\n\nHashable = _alias(collections.abc.Hashable, 0)  # Not generic.\nAwaitable = _alias(collections.abc.Awaitable, 1)\nCoroutine = _alias(collections.abc.Coroutine, 3)\nAsyncIterable = _alias(collections.abc.AsyncIterable, 1)\nAsyncIterator = _alias(collections.abc.AsyncIterator, 1)\nIterable = _alias(collections.abc.Iterable, 1)\nIterator = _alias(collections.abc.Iterator, 1)\nReversible = _alias(collections.abc.Reversible, 1)\nSized = _alias(collections.abc.Sized, 0)  # Not generic.\nContainer = _alias(collections.abc.Container, 1)\nCollection = _alias(collections.abc.Collection, 1)\nCallable = _CallableType(collections.abc.Callable, 2)\nCallable.__doc__ = \\\n    \"\"\"Deprecated alias to collections.abc.Callable.\n\n    Callable[[int], str] signifies a function that takes a single\n    parameter of type int and returns a str.\n\n    The subscription syntax must always be used with exactly two\n    values: the argument list and the return type.\n    The argument list must be a list of types, a ParamSpec,\n    Concatenate or ellipsis. The return type must be a single type.\n\n    There is no syntax to indicate optional or keyword arguments;\n    such function types are rarely used as callback types.\n    \"\"\"\nAbstractSet = _alias(collections.abc.Set, 1, name='AbstractSet')\nMutableSet = _alias(collections.abc.MutableSet, 1)\n# NOTE: Mapping is only covariant in the value type.\nMapping = _alias(collections.abc.Mapping, 2)\nMutableMapping = _alias(collections.abc.MutableMapping, 2)\nSequence = _alias(collections.abc.Sequence, 1)\nMutableSequence = _alias(collections.abc.MutableSequence, 1)\nByteString = _alias(collections.abc.ByteString, 0)  # Not generic\n# Tuple accepts variable number of parameters.\nTuple = _TupleType(tuple, -1, inst=False, name='Tuple')\nTuple.__doc__ = \\\n    \"\"\"Deprecated alias to builtins.tuple.\n\n    Tuple[X, Y] is the cross-product type of X and Y.\n\n    Example: Tuple[T1, T2] is a tuple of two elements corresponding\n    to type variables T1 and T2.  Tuple[int, float, str] is a tuple\n    of an int, a float and a string.\n\n    To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].\n    \"\"\"\nList = _alias(list, 1, inst=False, name='List')\nDeque = _alias(collections.deque, 1, name='Deque')\nSet = _alias(set, 1, inst=False, name='Set')\nFrozenSet = _alias(frozenset, 1, inst=False, name='FrozenSet')\nMappingView = _alias(collections.abc.MappingView, 1)\nKeysView = _alias(collections.abc.KeysView, 1)\nItemsView = _alias(collections.abc.ItemsView, 2)\nValuesView = _alias(collections.abc.ValuesView, 1)\nContextManager = _alias(contextlib.AbstractContextManager, 1, name='ContextManager')\nAsyncContextManager = _alias(contextlib.AbstractAsyncContextManager, 1, name='AsyncContextManager')\nDict = _alias(dict, 2, inst=False, name='Dict')\nDefaultDict = _alias(collections.defaultdict, 2, name='DefaultDict')\nOrderedDict = _alias(collections.OrderedDict, 2)\nCounter = _alias(collections.Counter, 1)\nChainMap = _alias(collections.ChainMap, 2)\nGenerator = _alias(collections.abc.Generator, 3)\nAsyncGenerator = _alias(collections.abc.AsyncGenerator, 2)\nType = _alias(type, 1, inst=False, name='Type')\nType.__doc__ = \\\n    \"\"\"Deprecated alias to builtins.type.\n\n    builtins.type or typing.Type can be used to annotate class objects.\n    For example, suppose we have the following classes::\n\n        class User: ...  # Abstract base for User classes\n        class BasicUser(User): ...\n        class ProUser(User): ...\n        class TeamUser(User): ...\n\n    And a function that takes a class argument that's a subclass of\n    User and returns an instance of the corresponding class::\n\n        U = TypeVar('U', bound=User)\n        def new_user(user_class: Type[U]) -> U:\n            user = user_class()\n            # (Here we could write the user object to a database)\n            return user\n\n        joe = new_user(BasicUser)\n\n    At this point the type checker knows that joe has type BasicUser.\n    \"\"\"\n\n\n@runtime_checkable\nclass SupportsInt(Protocol):\n    \"\"\"An ABC with one abstract method __int__.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __int__(self) -> int:\n        pass\n\n\n@runtime_checkable\nclass SupportsFloat(Protocol):\n    \"\"\"An ABC with one abstract method __float__.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __float__(self) -> float:\n        pass\n\n\n@runtime_checkable\nclass SupportsComplex(Protocol):\n    \"\"\"An ABC with one abstract method __complex__.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __complex__(self) -> complex:\n        pass\n\n\n@runtime_checkable\nclass SupportsBytes(Protocol):\n    \"\"\"An ABC with one abstract method __bytes__.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __bytes__(self) -> bytes:\n        pass\n\n\n@runtime_checkable\nclass SupportsIndex(Protocol):\n    \"\"\"An ABC with one abstract method __index__.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __index__(self) -> int:\n        pass\n\n\n@runtime_checkable\nclass SupportsAbs(Protocol[T_co]):\n    \"\"\"An ABC with one abstract method __abs__ that is covariant in its return type.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __abs__(self) -> T_co:\n        pass\n\n\n@runtime_checkable\nclass SupportsRound(Protocol[T_co]):\n    \"\"\"An ABC with one abstract method __round__ that is covariant in its return type.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def __round__(self, ndigits: int = 0) -> T_co:\n        pass\n\n\ndef _make_nmtuple(name, types, module, defaults = ()):\n    fields = [n for n, t in types]\n    types = {n: _type_check(t, f\"field {n} annotation must be a type\")\n             for n, t in types}\n    nm_tpl = collections.namedtuple(name, fields,\n                                    defaults=defaults, module=module)\n    nm_tpl.__annotations__ = nm_tpl.__new__.__annotations__ = types\n    return nm_tpl\n\n\n# attributes prohibited to set in NamedTuple class syntax\n_prohibited = frozenset({'__new__', '__init__', '__slots__', '__getnewargs__',\n                         '_fields', '_field_defaults',\n                         '_make', '_replace', '_asdict', '_source'})\n\n_special = frozenset({'__module__', '__name__', '__annotations__'})\n\n\nclass NamedTupleMeta(type):\n    def __new__(cls, typename, bases, ns):\n        assert _NamedTuple in bases\n        for base in bases:\n            if base is not _NamedTuple and base is not Generic:\n                raise TypeError(\n                    'can only inherit from a NamedTuple type and Generic')\n        bases = tuple(tuple if base is _NamedTuple else base for base in bases)\n        types = ns.get('__annotations__', {})\n        default_names = []\n        for field_name in types:\n            if field_name in ns:\n                default_names.append(field_name)\n            elif default_names:\n                raise TypeError(f\"Non-default namedtuple field {field_name} \"\n                                f\"cannot follow default field\"\n                                f\"{'s' if len(default_names) > 1 else ''} \"\n                                f\"{', '.join(default_names)}\")\n        nm_tpl = _make_nmtuple(typename, types.items(),\n                               defaults=[ns[n] for n in default_names],\n                               module=ns['__module__'])\n        nm_tpl.__bases__ = bases\n        if Generic in bases:\n            class_getitem = Generic.__class_getitem__.__func__\n            nm_tpl.__class_getitem__ = classmethod(class_getitem)\n        # update from user namespace without overriding special namedtuple attributes\n        for key in ns:\n            if key in _prohibited:\n                raise AttributeError(\"Cannot overwrite NamedTuple attribute \" + key)\n            elif key not in _special and key not in nm_tpl._fields:\n                setattr(nm_tpl, key, ns[key])\n        if Generic in bases:\n            nm_tpl.__init_subclass__()\n        return nm_tpl\n\n\ndef NamedTuple(typename, fields=None, /, **kwargs):\n    \"\"\"Typed version of namedtuple.\n\n    Usage::\n\n        class Employee(NamedTuple):\n            name: str\n            id: int\n\n    This is equivalent to::\n\n        Employee = collections.namedtuple('Employee', ['name', 'id'])\n\n    The resulting class has an extra __annotations__ attribute, giving a\n    dict that maps field names to types.  (The field names are also in\n    the _fields attribute, which is part of the namedtuple API.)\n    An alternative equivalent functional syntax is also accepted::\n\n        Employee = NamedTuple('Employee', [('name', str), ('id', int)])\n    \"\"\"\n    if fields is None:\n        fields = kwargs.items()\n    elif kwargs:\n        raise TypeError(\"Either list of fields or keywords\"\n                        \" can be provided to NamedTuple, not both\")\n    return _make_nmtuple(typename, fields, module=_caller())\n\n_NamedTuple = type.__new__(NamedTupleMeta, 'NamedTuple', (), {})\n\ndef _namedtuple_mro_entries(bases):\n    assert NamedTuple in bases\n    return (_NamedTuple,)\n\nNamedTuple.__mro_entries__ = _namedtuple_mro_entries\n\n\nclass _TypedDictMeta(type):\n    def __new__(cls, name, bases, ns, total=True):\n        \"\"\"Create a new typed dict class object.\n\n        This method is called when TypedDict is subclassed,\n        or when TypedDict is instantiated. This way\n        TypedDict supports all three syntax forms described in its docstring.\n        Subclasses and instances of TypedDict return actual dictionaries.\n        \"\"\"\n        for base in bases:\n            if type(base) is not _TypedDictMeta and base is not Generic:\n                raise TypeError('cannot inherit from both a TypedDict type '\n                                'and a non-TypedDict base class')\n\n        if any(issubclass(b, Generic) for b in bases):\n            generic_base = (Generic,)\n        else:\n            generic_base = ()\n\n        tp_dict = type.__new__(_TypedDictMeta, name, (*generic_base, dict), ns)\n\n        annotations = {}\n        own_annotations = ns.get('__annotations__', {})\n        msg = \"TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type\"\n        own_annotations = {\n            n: _type_check(tp, msg, module=tp_dict.__module__)\n            for n, tp in own_annotations.items()\n        }\n        required_keys = set()\n        optional_keys = set()\n\n        for base in bases:\n            annotations.update(base.__dict__.get('__annotations__', {}))\n            required_keys.update(base.__dict__.get('__required_keys__', ()))\n            optional_keys.update(base.__dict__.get('__optional_keys__', ()))\n\n        annotations.update(own_annotations)\n        for annotation_key, annotation_type in own_annotations.items():\n            annotation_origin = get_origin(annotation_type)\n            if annotation_origin is Annotated:\n                annotation_args = get_args(annotation_type)\n                if annotation_args:\n                    annotation_type = annotation_args[0]\n                    annotation_origin = get_origin(annotation_type)\n\n            if annotation_origin is Required:\n                required_keys.add(annotation_key)\n            elif annotation_origin is NotRequired:\n                optional_keys.add(annotation_key)\n            elif total:\n                required_keys.add(annotation_key)\n            else:\n                optional_keys.add(annotation_key)\n\n        tp_dict.__annotations__ = annotations\n        tp_dict.__required_keys__ = frozenset(required_keys)\n        tp_dict.__optional_keys__ = frozenset(optional_keys)\n        if not hasattr(tp_dict, '__total__'):\n            tp_dict.__total__ = total\n        return tp_dict\n\n    __call__ = dict  # static method\n\n    def __subclasscheck__(cls, other):\n        # Typed dicts are only for static structural subtyping.\n        raise TypeError('TypedDict does not support instance and class checks')\n\n    __instancecheck__ = __subclasscheck__\n\n\ndef TypedDict(typename, fields=None, /, *, total=True, **kwargs):\n    \"\"\"A simple typed namespace. At runtime it is equivalent to a plain dict.\n\n    TypedDict creates a dictionary type such that a type checker will expect all\n    instances to have a certain set of keys, where each key is\n    associated with a value of a consistent type. This expectation\n    is not checked at runtime.\n\n    Usage::\n\n        class Point2D(TypedDict):\n            x: int\n            y: int\n            label: str\n\n        a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK\n        b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check\n\n        assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')\n\n    The type info can be accessed via the Point2D.__annotations__ dict, and\n    the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.\n    TypedDict supports an additional equivalent form::\n\n        Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})\n\n    By default, all keys must be present in a TypedDict. It is possible\n    to override this by specifying totality::\n\n        class Point2D(TypedDict, total=False):\n            x: int\n            y: int\n\n    This means that a Point2D TypedDict can have any of the keys omitted. A type\n    checker is only expected to support a literal False or True as the value of\n    the total argument. True is the default, and makes all items defined in the\n    class body be required.\n\n    The Required and NotRequired special forms can also be used to mark\n    individual keys as being required or not required::\n\n        class Point2D(TypedDict):\n            x: int               # the \"x\" key must always be present (Required is the default)\n            y: NotRequired[int]  # the \"y\" key can be omitted\n\n    See PEP 655 for more details on Required and NotRequired.\n    \"\"\"\n    if fields is None:\n        fields = kwargs\n    elif kwargs:\n        raise TypeError(\"TypedDict takes either a dict or keyword arguments,\"\n                        \" but not both\")\n    if kwargs:\n        warnings.warn(\n            \"The kwargs-based syntax for TypedDict definitions is deprecated \"\n            \"in Python 3.11, will be removed in Python 3.13, and may not be \"\n            \"understood by third-party type checkers.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n\n    ns = {'__annotations__': dict(fields)}\n    module = _caller()\n    if module is not None:\n        # Setting correct module is necessary to make typed dict classes pickleable.\n        ns['__module__'] = module\n\n    return _TypedDictMeta(typename, (), ns, total=total)\n\n_TypedDict = type.__new__(_TypedDictMeta, 'TypedDict', (), {})\nTypedDict.__mro_entries__ = lambda bases: (_TypedDict,)\n\n\n@_SpecialForm\ndef Required(self, parameters):\n    \"\"\"Special typing construct to mark a TypedDict key as required.\n\n    This is mainly useful for total=False TypedDicts.\n\n    For example::\n\n        class Movie(TypedDict, total=False):\n            title: Required[str]\n            year: int\n\n        m = Movie(\n            title='The Matrix',  # typechecker error if key is omitted\n            year=1999,\n        )\n\n    There is no runtime checking that a required key is actually provided\n    when instantiating a related TypedDict.\n    \"\"\"\n    item = _type_check(parameters, f'{self._name} accepts only a single type.')\n    return _GenericAlias(self, (item,))\n\n\n@_SpecialForm\ndef NotRequired(self, parameters):\n    \"\"\"Special typing construct to mark a TypedDict key as potentially missing.\n\n    For example::\n\n        class Movie(TypedDict):\n            title: str\n            year: NotRequired[int]\n\n        m = Movie(\n            title='The Matrix',  # typechecker error if key is omitted\n            year=1999,\n        )\n    \"\"\"\n    item = _type_check(parameters, f'{self._name} accepts only a single type.')\n    return _GenericAlias(self, (item,))\n\n\nclass NewType:\n    \"\"\"NewType creates simple unique types with almost zero runtime overhead.\n\n    NewType(name, tp) is considered a subtype of tp\n    by static type checkers. At runtime, NewType(name, tp) returns\n    a dummy callable that simply returns its argument.\n\n    Usage::\n\n        UserId = NewType('UserId', int)\n\n        def name_by_id(user_id: UserId) -> str:\n            ...\n\n        UserId('user')          # Fails type check\n\n        name_by_id(42)          # Fails type check\n        name_by_id(UserId(42))  # OK\n\n        num = UserId(5) + 1     # type: int\n    \"\"\"\n\n    __call__ = _idfunc\n\n    def __init__(self, name, tp):\n        self.__qualname__ = name\n        if '.' in name:\n            name = name.rpartition('.')[-1]\n        self.__name__ = name\n        self.__supertype__ = tp\n        def_mod = _caller()\n        if def_mod != 'typing':\n            self.__module__ = def_mod\n\n    def __mro_entries__(self, bases):\n        # We defined __mro_entries__ to get a better error message\n        # if a user attempts to subclass a NewType instance. bpo-46170\n        superclass_name = self.__name__\n\n        class Dummy:\n            def __init_subclass__(cls):\n                subclass_name = cls.__name__\n                raise TypeError(\n                    f\"Cannot subclass an instance of NewType. Perhaps you were looking for: \"\n                    f\"`{subclass_name} = NewType({subclass_name!r}, {superclass_name})`\"\n                )\n\n        return (Dummy,)\n\n    def __repr__(self):\n        return f'{self.__module__}.{self.__qualname__}'\n\n    def __reduce__(self):\n        return self.__qualname__\n\n    def __or__(self, other):\n        return Union[self, other]\n\n    def __ror__(self, other):\n        return Union[other, self]\n\n\n# Python-version-specific alias (Python 2: unicode; Python 3: str)\nText = str\n\n\n# Constant that's True when type checking, but False here.\nTYPE_CHECKING = False\n\n\nclass IO(Generic[AnyStr]):\n    \"\"\"Generic base class for TextIO and BinaryIO.\n\n    This is an abstract, generic version of the return of open().\n\n    NOTE: This does not distinguish between the different possible\n    classes (text vs. binary, read vs. write vs. read/write,\n    append-only, unbuffered).  The TextIO and BinaryIO subclasses\n    below capture the distinctions between text vs. binary, which is\n    pervasive in the interface; however we currently do not offer a\n    way to track the other distinctions in the type system.\n    \"\"\"\n\n    __slots__ = ()\n\n    @property\n    @abstractmethod\n    def mode(self) -> str:\n        pass\n\n    @property\n    @abstractmethod\n    def name(self) -> str:\n        pass\n\n    @abstractmethod\n    def close(self) -> None:\n        pass\n\n    @property\n    @abstractmethod\n    def closed(self) -> bool:\n        pass\n\n    @abstractmethod\n    def fileno(self) -> int:\n        pass\n\n    @abstractmethod\n    def flush(self) -> None:\n        pass\n\n    @abstractmethod\n    def isatty(self) -> bool:\n        pass\n\n    @abstractmethod\n    def read(self, n: int = -1) -> AnyStr:\n        pass\n\n    @abstractmethod\n    def readable(self) -> bool:\n        pass\n\n    @abstractmethod\n    def readline(self, limit: int = -1) -> AnyStr:\n        pass\n\n    @abstractmethod\n    def readlines(self, hint: int = -1) -> List[AnyStr]:\n        pass\n\n    @abstractmethod\n    def seek(self, offset: int, whence: int = 0) -> int:\n        pass\n\n    @abstractmethod\n    def seekable(self) -> bool:\n        pass\n\n    @abstractmethod\n    def tell(self) -> int:\n        pass\n\n    @abstractmethod\n    def truncate(self, size: int = None) -> int:\n        pass\n\n    @abstractmethod\n    def writable(self) -> bool:\n        pass\n\n    @abstractmethod\n    def write(self, s: AnyStr) -> int:\n        pass\n\n    @abstractmethod\n    def writelines(self, lines: List[AnyStr]) -> None:\n        pass\n\n    @abstractmethod\n    def __enter__(self) -> 'IO[AnyStr]':\n        pass\n\n    @abstractmethod\n    def __exit__(self, type, value, traceback) -> None:\n        pass\n\n\nclass BinaryIO(IO[bytes]):\n    \"\"\"Typed version of the return of open() in binary mode.\"\"\"\n\n    __slots__ = ()\n\n    @abstractmethod\n    def write(self, s: Union[bytes, bytearray]) -> int:\n        pass\n\n    @abstractmethod\n    def __enter__(self) -> 'BinaryIO':\n        pass\n\n\nclass TextIO(IO[str]):\n    \"\"\"Typed version of the return of open() in text mode.\"\"\"\n\n    __slots__ = ()\n\n    @property\n    @abstractmethod\n    def buffer(self) -> BinaryIO:\n        pass\n\n    @property\n    @abstractmethod\n    def encoding(self) -> str:\n        pass\n\n    @property\n    @abstractmethod\n    def errors(self) -> Optional[str]:\n        pass\n\n    @property\n    @abstractmethod\n    def line_buffering(self) -> bool:\n        pass\n\n    @property\n    @abstractmethod\n    def newlines(self) -> Any:\n        pass\n\n    @abstractmethod\n    def __enter__(self) -> 'TextIO':\n        pass\n\n\nclass _DeprecatedType(type):\n    def __getattribute__(cls, name):\n        if name not in (\"__dict__\", \"__module__\") and name in cls.__dict__:\n            warnings.warn(\n                f\"{cls.__name__} is deprecated, import directly \"\n                f\"from typing instead. {cls.__name__} will be removed \"\n                \"in Python 3.12.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n        return super().__getattribute__(name)\n\n\nclass io(metaclass=_DeprecatedType):\n    \"\"\"Wrapper namespace for IO generic classes.\"\"\"\n\n    __all__ = ['IO', 'TextIO', 'BinaryIO']\n    IO = IO\n    TextIO = TextIO\n    BinaryIO = BinaryIO\n\n\nio.__name__ = __name__ + '.io'\nsys.modules[io.__name__] = io\n\nPattern = _alias(stdlib_re.Pattern, 1)\nMatch = _alias(stdlib_re.Match, 1)\n\nclass re(metaclass=_DeprecatedType):\n    \"\"\"Wrapper namespace for re type aliases.\"\"\"\n\n    __all__ = ['Pattern', 'Match']\n    Pattern = Pattern\n    Match = Match\n\n\nre.__name__ = __name__ + '.re'\nsys.modules[re.__name__] = re\n\n\ndef reveal_type(obj: T, /) -> T:\n    \"\"\"Reveal the inferred type of a variable.\n\n    When a static type checker encounters a call to ``reveal_type()``,\n    it will emit the inferred type of the argument::\n\n        x: int = 1\n        reveal_type(x)\n\n    Running a static type checker (e.g., mypy) on this example\n    will produce output similar to 'Revealed type is \"builtins.int\"'.\n\n    At runtime, the function prints the runtime type of the\n    argument and returns it unchanged.\n    \"\"\"\n    print(f\"Runtime type is {type(obj).__name__!r}\", file=sys.stderr)\n    return obj\n\n\ndef dataclass_transform(\n    *,\n    eq_default: bool = True,\n    order_default: bool = False,\n    kw_only_default: bool = False,\n    field_specifiers: tuple[type[Any] | Callable[..., Any], ...] = (),\n    **kwargs: Any,\n) -> Callable[[T], T]:\n    \"\"\"Decorator to mark an object as providing dataclass-like behaviour.\n\n    The decorator can be applied to a function, class, or metaclass.\n\n    Example usage with a decorator function::\n\n        T = TypeVar(\"T\")\n\n        @dataclass_transform()\n        def create_model(cls: type[T]) -> type[T]:\n            ...\n            return cls\n\n        @create_model\n        class CustomerModel:\n            id: int\n            name: str\n\n    On a base class::\n\n        @dataclass_transform()\n        class ModelBase: ...\n\n        class CustomerModel(ModelBase):\n            id: int\n            name: str\n\n    On a metaclass::\n\n        @dataclass_transform()\n        class ModelMeta(type): ...\n\n        class ModelBase(metaclass=ModelMeta): ...\n\n        class CustomerModel(ModelBase):\n            id: int\n            name: str\n\n    The ``CustomerModel`` classes defined above will\n    be treated by type checkers similarly to classes created with\n    ``@dataclasses.dataclass``.\n    For example, type checkers will assume these classes have\n    ``__init__`` methods that accept ``id`` and ``name``.\n\n    The arguments to this decorator can be used to customize this behavior:\n    - ``eq_default`` indicates whether the ``eq`` parameter is assumed to be\n        ``True`` or ``False`` if it is omitted by the caller.\n    - ``order_default`` indicates whether the ``order`` parameter is\n        assumed to be True or False if it is omitted by the caller.\n    - ``kw_only_default`` indicates whether the ``kw_only`` parameter is\n        assumed to be True or False if it is omitted by the caller.\n    - ``field_specifiers`` specifies a static list of supported classes\n        or functions that describe fields, similar to ``dataclasses.field()``.\n    - Arbitrary other keyword arguments are accepted in order to allow for\n        possible future extensions.\n\n    At runtime, this decorator records its arguments in the\n    ``__dataclass_transform__`` attribute on the decorated object.\n    It has no other runtime effect.\n\n    See PEP 681 for more details.\n    \"\"\"\n    def decorator(cls_or_fn):\n        cls_or_fn.__dataclass_transform__ = {\n            \"eq_default\": eq_default,\n            \"order_default\": order_default,\n            \"kw_only_default\": kw_only_default,\n            \"field_specifiers\": field_specifiers,\n            \"kwargs\": kwargs,\n        }\n        return cls_or_fn\n    return decorator\n", 3487], "C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py": ["from typing import List\n\n\nclass Solution(object):\n    def calPoints(self, operations: List[str]) -> int:\n        stack = []\n        for val in operations:\n            if val == 'C':\n                stack.pop()\n            elif val == 'D':\n                stack.append(stack[-1] * 2)\n            elif val == '+':\n                stack.append(stack[-1] + stack[-2])\n            else:\n                stack.append(int(val))\n        return sum(stack)\n\n\nif __name__ == '__main__':\n    def test_cal_points():\n        # case\n        ops = [\"5\", \"2\", \"C\", \"D\", \"+\"]\n        assert Solution().calPoints(ops) == 30\n\n        # case\n        ops = [\"5\", \"-2\", \"4\", \"C\", \"D\", \"9\", \"+\", \"+\"]\n        assert Solution().calPoints(ops) == 27\n\n        print('Succeed')\n\n\n    test_cal_points()\n", 32]}, "functions": {"inner (C:\\Users\\charles\\.conda\\envs\\demo\\Lib\\typing.py:352)": ["C:\\Users\\charles\\.conda\\envs\\demo\\Lib\\typing.py", 352], "Solution (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:4)": ["C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py", 4], "calPoints (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:5)": ["C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py", 5], "test_cal_points (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:20)": ["C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py", 20], "<module> (C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py:1)": ["C:\\Users\\charles\\Yifan\\Project\\leetcode\\py\\C 601-900\\0682 Baseball Game\\demo.py", 1]}}}